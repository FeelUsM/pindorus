{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Зачем всё это?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Есть машинный перевод и есть автоматизированный перевод. \n",
    "\n",
    "Машинный перевод дает 100% автоматизации и не позволяет вмешиваться в процесс перевода (только в результат). Конечно у многих машинных переводчиков есть функция \"предложить перевод\", но я не понимаю, как она работает, и работает ли хоть как-то вообще. Однажды я всё-таки заметил, как это работает: в яндекс-переводчике предложил перевод слова (уже не помню какого), и через сутки до него дошло, как надо переводить это слово. Через сутки, Карл!\n",
    "\n",
    "Автоматизированный перевод дает где-то 15-20% автоматизации. Помимо словарей, глоссариев и прочей справочной информации, самая продвинутая (известная мне) технология - это память переводов, когда человек вручную переводит предложения, а система запоминает эти переводы, и если встречается предложение, которое было переведено раньше (или _похожее_ на него), его перевод подставляется автоматически. Но какова вероятность встретить в тексте 2 одинаковых предложения, если в них больше трёх слов?\n",
    "\n",
    "Целью данного переводчика является автоматизация 90%. Не 100 и не 20. А также мгновенное вступление изменений в силу. Ну и возможность залезть в код.\n",
    "\n",
    "-----\n",
    "\n",
    "Любая система перевода состоит из двух аспектов:\n",
    "* используемые структуры данных и алгоритмы\n",
    "* способ заполнения базы данных\n",
    "\n",
    "Есть следующие способы заполнения базы данных:\n",
    "* статистический: у статистического перевода и у нейросетевого\n",
    "* ручной: у перевода основанного на пправилах и у памяти переводов\n",
    "\n",
    "Какими бы умными ни были нейросетевые системы, системы с ручным заполнением базы данных всегда будут оставаться актуальными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Основной принцип"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "p_паттерн парсит текст (str, pos), \n",
    "    вызывая другие паттерны, возвращающие древовидные структуры\n",
    "    эти древовидные структуры передает одному из правил, сопоставленных данному паттерну\n",
    "    и возвращает (pos, результат этого правила), помещенный в массив\n",
    "    \n",
    "    если ничего не удалось распарсить, возвращаемый массив будет пустым\n",
    "    если удалось распарсить несколько вариантов - в массиве будет насколько вариантов\n",
    "        сначала парсятся все обычные варианты\n",
    "        и если есть хоть один обычный результат, \n",
    "            то парсятся все исключения\n",
    "            в массиве результатов исключения замещают результаты, если их длины совпадают\n",
    "```\n",
    "\n",
    "```\n",
    "r_правило получает список древовидных структур\n",
    "    обрабатывает их по определенному правилу\n",
    "        т.е. меняет параметры аргументов\n",
    "    возвращает древовидную структуру\n",
    "        т.е. создает структуру, содержащую в себе аргументы\n",
    "    если в группе правил все правила отключены, то результатом будет 0 или ссылка на эту группу правил\n",
    "    отключать все правила допустимо только в исключениях\n",
    "```\n",
    "\n",
    "```\n",
    "древовидная структура - объект определенного класса, соответствующего части речи, который содержит\n",
    "    постоянные параметры (для сущ.: род, число)\n",
    "    переменные параметры (для сущ.: падеж)\n",
    "        при изменении этих параметров автоматически менются параметры дочерних древовидных структур\n",
    "    talk: массив древовидных структур\n",
    "        или пар (тип, структура), где тип - main/dep/other\n",
    "    и др.\n",
    "```\n",
    "\n",
    "```\n",
    "str(древовидная структура)\n",
    "    превращает древовидную структуру в строку\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Что с этим делать дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "В дальнейшем предполагается, что паттерны и правила будут писать пользователи\n",
    "грамматика не преобразовывается в LL(1) или какой-то другой промежуточный формат,\n",
    "а парсится как есть, с возвратами (LL(*)), поэтому результаты нетерминалов кэшируются.\n",
    "Также стоит защита от зацикливания.\n",
    "Никто не обещал, что грамматика будет однозначной, \n",
    "поэтому каждый нетерминал возвращает массив результатов.\n",
    "Но в конечном итоге таких результатов должно быть немного.\n",
    "Ситуация, когда получаются одинаковые результаты явлется нежелательной.\n",
    "\n",
    "Уточним терминологию:\n",
    "нетерминал - набор альтернатив паттернов\n",
    "паттерн - последовательность терминалов/нетерминалов\n",
    "\n",
    "В дальнейшем предполагается, что будет центральная грамматика, \n",
    "а у ее правил пользователи будут создавать исключения и расширения.\n",
    "Фишка в том, что при редактировании грамматики этим способом \n",
    "    поведение грамматики для уже имеющихся тестов/текстов не изменится.\n",
    "Возможно периодически для оптимизации грамматики будет требоваться полная ее переработка,\n",
    "но чисто математическая (т.е. не требующая тестов/текстов) и довольно вычислительно-сложная задача.\n",
    "Впрочем и без оптимизации производительность ухудшается не сильно.\n",
    "\n",
    "Паттерн A является исключением паттерна B, если \n",
    "всё что может разобрать паттерн A может разобрать паттерн B,\n",
    "т.е. A задает подъязык языка B, \n",
    "т.е. A является частным случаем B (но связано с другим правилом).\n",
    "Сначала парсится B, и если это оказалось удачным, парсится A.\n",
    "Если А распарсилось неудачно, то результатом станосится результат B,\n",
    "а если удачно - то результат B отбрасывается и результатом станосится результат A.\n",
    "\n",
    "т.к. исключения являются обычными нетерминалами, то внутри них тоже можно делать исключения\n",
    "\n",
    "Расширения просто добавляются в список альтернатив.\n",
    "Можно было бы просто в нетерминалы добавлять новые альтернативы, \n",
    "но это может привести к появлению разных вариантов разбора.\n",
    "В этих случаях можно было бы создавать исклчения, разрешающие неоднозначность,\n",
    "но чтобы всё происходило автоматически для уже переведенных текстов\n",
    "надо чтобы результат помечался датой, которая является максимумом \n",
    "    из дат результатов (которые разобрал паттерн-последовательность) и даты создания этого паттерна.\n",
    "Если в альтернативу попадают результаты одинаковой длины, то \n",
    "    новые отбрасываются и остается только старый.\n",
    "\n",
    "В дальнейшем предполагается возможность каждый паттерн связывать с \n",
    "набором правил, а точнее с одним правилом из заданного набора.\n",
    "А также возможность эти наборы пополнять и легко менять вариант перевода.\n",
    "Одним из правил перевода исключения будет вариант, когда\n",
    "результат исключения отбрасывается а результатом становится \n",
    "результат правила регулярного паттерна.\n",
    "Это дает возможность отключать исключения, т.к. они всё же вносят изменения в регулярный перевод.\n",
    "\n",
    "Семантически возникают разные варианты использования наборов правил:\n",
    "- смысловой\n",
    "    в этом случае как правило смысл паттерна не меняется на протяжении всего текста\n",
    "- указательный (контекстный): it, this, that, you\n",
    "    ...\n",
    "- эстетический\n",
    "    его решать лучше за счет более крупных исключений (?)\n",
    "\n",
    "Вопрос дефолтного связывания паттернов с правилами допускает множество решений\n",
    "и остается открытым.\n",
    "В любом случае пользователь сможет создавать исключения паттернов и дополнительные правила,\n",
    "тем самым пополняя базу данных переводчика,\n",
    "а также менять связи паттернов с правилами для своего текста, сохранять эти связи,\n",
    "и применять к другим текстам.\n",
    "\n",
    "набор правил - набор правил + номер дефолтного правила\n",
    "\t\tили просто правило\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Организация кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* parse_system.py - низкоуровневые классы, токенезация и базовые функции парсинга\n",
    "* classes.py - классы частей речи\n",
    "* ru_dictionary.py - функции отображения, русские слова и функции их добавления\n",
    "* en_dictionary.py - словарь\n",
    "\n",
    "\n",
    "* en2ru.ipynb .py - описание всего, грамматика, маленькие тесты, todo\n",
    "* tests.ipynb - тесты уже имеющихся переводов\n",
    "* utils.ipynb - прочее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:34.907832Z",
     "start_time": "2019-10-15T17:37:34.903832Z"
    }
   },
   "outputs": [],
   "source": [
    "'''англо-русский переводчик, основанный на правилах, с простым добавлением паттернов и правил\n",
    "\n",
    "en2ru(s) -> str - переводит строку, возвращает строку\n",
    "d_en2ru(s) -> str - дополнительно печатает отладочный вывод\n",
    "pr_l_repr(s) - печатает строку в тройных кавычках\n",
    "decline(s,pads=['ip','rp','dp','vp','tp','pp']) - возвращает список склонений переведенной фразы\n",
    "parse_pat(patt,s) -> Struct - парсит строку паттерном, возвращает нестрингифицированный объект\n",
    "d_parse_pat(patt,s) -> Struct - дополнительно печатает отладочный вывод\n",
    "scheme(s) - печатает схему разбора строки\n",
    "\n",
    "паттерны:\n",
    "p_text\n",
    "p_sentence\n",
    "p_phrase\n",
    "p_verb\n",
    "...\n",
    "p_noun\n",
    "...\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.019838Z",
     "start_time": "2019-10-15T17:37:34.915832Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import parse_system\n",
    "from parse_system import S, SAttrs, ParseInfo, tokenize,\\\n",
    "                        ch_title, ch_sentence, ch_anti_sentence, ch_open, ch_prefix, ch_anti_prefix,\\\n",
    "                        seq, alt, p_alt, ELSE, W, D,\\\n",
    "                        warning, debug_pp, reset_globals, global_cache, \\\n",
    "                        RuleVars, RuleContext, repr_rule, rez_checker\n",
    "\n",
    "import classes\n",
    "from classes import StC, StNum, StNoun, StAdj, StVerb, I\n",
    "\n",
    "import ru_dictionary\n",
    "from ru_dictionary import ruwords, CW, add_runoun2, add_skl2, make_skl2\n",
    "\n",
    "import en_dictionary\n",
    "from en_dictionary import dict_adj, dict_adv, dict_noun, dict_pronoun_ip, dict_pronoun_dp, \\\n",
    "                        dict_numeral, dict_verb_simple, dict_verb_komu, r_adj_noun, dict_other,\\\n",
    "                        add_ennoun2, add_ennoun1, add_dict_variant\n",
    "from importlib import reload\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "def dict_funs(*funs):\n",
    "    return {fun.__name__:fun for fun in funs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Паттерны и правила: Составные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "паттерн - функция, которая принимает s,p(токенизированную строку и позицию в ней)   \n",
    "и возвращает список результатов, а именно список пар (позиция окончания разбора, результат)  \n",
    "токены - объекты типа S - нормализованные (т.е. в нижнем регистре) строки с дополнительными атрибутами, а именно префикс из пробельных символов, модификаторы, восстанавливающие исходный регистр слова, тэги, в которые обёрнуто это слово (тэги пока не реализованы)  \n",
    "если `f` - паттерн, то `f(s,p)` - его вызов, или его результат  \n",
    "длиной результата будем называть разность позиции окончания разбора и стартовой позиции.\n",
    "\n",
    "Терминальные паттерны:  \n",
    "`W('строка')` - считывает 1 токен, который должен совпадать со сторокой, возвращает его в непреобразованном виде, а именно объект класса S\n",
    "\n",
    "`D(dict_smth)` - считывает 1 токен, ищет его в словаре `dict_smth`, и если находит, возвращает то, что ему сопоставлено.  \n",
    "список доступных словарей можно посмотреть в en_dictionary.py\n",
    "\n",
    "Нетерминальные паттрны:  \n",
    "`alt(patt1,patt2,ELSE,patt3,patt4)` - список альтернатив, объединяет результаты паттернов. `ELSE` - ключевое слово-разделитель. Паттрены слева от ELSE являются исключениями паттернов справа, регулярных паттернов. Исключения могут отсутствовать, в этом случае `ELSE` указывать не нужно. Если ни один из регулярных паттернов не разобран, паттерны-исключения парсится не будут. Результаты паттернов исключений замещают результаты регулярных паттернов, но только той же самой длины прочтения. Если результат исключения не может заместить ни один из регулярных результатов, генерируется предупреждение.  \n",
    "`p_alt(s,p,patt1,patt2,ELSE,patt3,patt4)` эквивалентен `alt(patt1,patt2,ELSE,patt3,patt4)(s,p)`\n",
    "\n",
    "`seq([patt1,patt2,patt3],rule)`(где `def rule(rez1,rez2,rez3)`) - последовательность паттернов. Генерируются все возможные комбинации результатов, и каждая последовательность передается в правило, и из этих результатов составляется окончательный результат.  \n",
    "Если нужно применить правило к результату одного паттерна, то для этого его надо поместить в последовательность из дного этого паттерна `seq([patt1],rule)` (где `rule(rez1)`)\n",
    "\n",
    "Правила:  \n",
    "правило получает результаты последовательно разобранных паттернов, и формирует из них единый объект, возможно предварительно проведя некоторые проверки, и сообщив их результаты warning-ом  \n",
    "\n",
    "объект должен быть класса (или подкласса Struct)  \n",
    "вот типичный синтаксис:  \n",
    "```\n",
    "return StSmth([\n",
    "    I(tag = rez1),\n",
    "    I(tag = rez2),\n",
    "    I(tag = rez3),\n",
    "],struct_params...)\n",
    "```\n",
    "-- это структура, состоящая из последовательности rez1, rez2, rez3  \n",
    "доступные типы структур, а также их синтаксис (`tag`, `struct_params`) можно посмотреть в classes.py  \n",
    "`tag` задает тип взаимодействия между родительской и дочерней структурой\n",
    "\n",
    "входные результаты можно указывать в любом порядке  \n",
    "можно менять их параметры: `I(dep = rez1, param1=new_val_1, param2 = new_val_2...)`  \n",
    "можно менять их атрибуты:  \n",
    "*    добавлять атрибуты с более правого объекта `I(dep = rez1, attrs_from_right=rez2.attrs)`  \n",
    "*    добавлять атрибуты с более левого объекта `I(dep = rez2, attrs_from_left=rez1.attrs)` \n",
    "\n",
    "можно использовать фиксированные слова `I(nodep = S('строка', rez3.attrs))`, при этом снабжая (или не снабжая) их атрибутами одного из входных результатов.  \n",
    "можно использовать фиксированные объекты из словаря `I(dep = CW('кошка',rez3))`, при этом снабжая (или не снабжая) их атрибутами одного из входных результатов (в данном случае это rez3).  \n",
    "не обязательно все входящие результаты должны присутствовать в итоговом объекте. Чтобы их атрибуты не потерялись, их атрибуты можно добавлять к другим результатам, как показано выше.\n",
    "\n",
    "Может быть так, что чтруктура конструируется из нескольких фиксированных слов и одного результата. В этом случае мы часто хотим атрибуты этого результата распространить на всю структуру. Для этого в параметры структуры нужно добавить `pull_attrs=N`, где `N` - номер этого результата (нумерация с 0).\n",
    "Например\n",
    "```\n",
    "I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "]), pull_attrs=1 )\n",
    "```\n",
    "Если указать `pull_attrs=1`, то '__Kate__' будет переведено как '__у Кати__'  \n",
    "Если не указать `pull_attrs=1`, то '__Kate__' будет переведено как 'у __Кати__'\n",
    "\n",
    "Если требуется вернуть всего лишь один входной результат, изменив его параметры, он всё равно должен быть обёрнут в новую структуру\n",
    "\n",
    "Ну и, само собой, можно создавать структуры внутри которых содержатся структуры.\n",
    "\n",
    "------\n",
    "можно менять параметры входных объектов, но т.к. объекты кэшируются, их нельзя изменять, но можно указать, какие параметры будут изменены перед преобразованием объекта в строку, но для этого объект должен быть помещен в \n",
    "\n",
    "\n",
    "-Когда в правилах использовать S а когда один из классов Struct ?\n",
    "\n",
    "-S используется для неизменяемых узлов-листьев. Во всех остальных случаях используется один из классов Struct\n",
    "\n",
    "pull_attrs - если имеющуюся структуру надо расширить константами и распространить attrs структуры на расширенную структуру - смотри пример в как в r_U_noun_EST_noun\n",
    "значение pull_attrs задается равным исходной структуры в расширенной\n",
    "\n",
    "attrs_from_left/attrs_from_right - если в правиле один из аргументов пропадает, то его атрибуты желательно добавить к другому аргументу. \n",
    "Синтаксис `I(tag=remain_arg, ... , attrs_from_left=lost_arg.attrs)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.117844Z",
     "start_time": "2019-10-15T17:37:35.028839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, S('cat',SAttrs('',set(),set())))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W('cat')(tokenize('cat'),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## en_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### dict_noun\n",
    "###### dict_pronoun_ip\n",
    "###### dict_pronoun_dp\n",
    "###### dict_adj\n",
    "###### dict_numeral\n",
    "###### dict_verb_simple\n",
    "###### dict_verb_komu\n",
    "r_adj_noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_numeral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.211849Z",
     "start_time": "2019-10-15T17:37:35.154846Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_numeral(s,p):\n",
    "    return D(dict_numeral)(s,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### p_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.313855Z",
     "start_time": "2019-10-15T17:37:35.214849Z"
    }
   },
   "outputs": [],
   "source": [
    "#2->\n",
    "@debug_pp\n",
    "def p_adj(s,p): return p_alt(s,p,\n",
    "    D(dict_adj),\n",
    "    seq([D(dict_adv),p_adj],r_adv_adj)\n",
    ")\n",
    "def r_adv_adj(_adv,_adj): return StAdj([\n",
    "    I(nodep=_adv),\n",
    "    I(maindep=_adj)\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun-like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_adj_noun3\n",
    "r_A_noun, r_THE_noun, r_GOOD_MORNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.411861Z",
     "start_time": "2019-10-15T17:37:35.316855Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_adj_noun3(s,p): return p_alt(s,p,\n",
    "    seq([ alt(W('an'),W('a')), p_noun3 ],r_A_noun),\n",
    "    seq([ W('the')           , p_noun3 ],r_THE_noun),\n",
    "    seq([ W('good'), W('morning') ],r_GOOD_MORNING),             \n",
    "ELSE,\n",
    "    seq([ p_adj, p_noun3 ],r_adj_noun)\n",
    ")\n",
    "# r_adj_noun определен в en_dictionary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.522867Z",
     "start_time": "2019-10-15T17:37:35.420861Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# исключения\n",
    "def r_A_noun(_a,_n): return StNoun([\n",
    "    I(maindep=_n,         attrs_from_left=_a.attrs)\n",
    "])\n",
    "def r_THE_noun(_a,_n): return StNoun([\n",
    "    I(maindep=_n,         attrs_from_left=_a.attrs)\n",
    "])\n",
    "\n",
    "def r_GOOD_MORNING(_g,_m):  return r_adj_noun(\n",
    "    CW('добрый',_g),\n",
    "    CW('утро',_m)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_noun3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.660875Z",
     "start_time": "2019-10-15T17:37:35.531868Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun3(s,p): return p_alt(s,p,\n",
    "    p_adj_noun3, #ELSE, # переход к следующему уровню\n",
    "    p_adj, #ELSE, # переход к следующему уровню\n",
    "    p_numeral,\n",
    "    D(dict_noun)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_noun2_1\n",
    "r_noun_dops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.763881Z",
     "start_time": "2019-10-15T17:37:35.670875Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun2_1(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun3, p_dops ], r_noun_dops), #ELSE, # переход к следующему уровню\n",
    "    p_noun3\n",
    ")\n",
    "def r_noun_dops(n,d): return StNoun([\n",
    "    I(maindep=n),\n",
    "    I(nodep=d)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_noun2\n",
    "###### p_dop_noun2\n",
    "r_noun_numeral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.879887Z",
     "start_time": "2019-10-15T17:37:35.771881Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun2(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun2_1, p_numeral ], r_noun_numeral), #ELSE, # переход к следующему уровню\n",
    "    p_noun2_1\n",
    ")\n",
    "@debug_pp\n",
    "def p_dop_noun2(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun3, p_numeral ], r_noun_numeral), #ELSE, # переход к следующему уровню\n",
    "    p_noun3\n",
    ")\n",
    "def r_noun_numeral(n,num): return StNoun([\n",
    "    I(maindep=n),\n",
    "    I(nomer=num)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_noun1\n",
    "###### p_dop_noun1\n",
    "###### p_noun1_ip\n",
    "r_numeral_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:35.988894Z",
     "start_time": "2019-10-15T17:37:35.881888Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun1(s,p): return p_alt(s,p,\n",
    "    seq([ p_numeral, p_noun2 ], r_numeral_noun), #ELSE, # переход к следующему уровню\n",
    "    p_noun2,\n",
    "    D(dict_pronoun_dp)\n",
    ")\n",
    "@debug_pp\n",
    "def p_dop_noun1(s,p): return p_alt(s,p,\n",
    "    seq([ p_numeral, p_dop_noun2 ], r_numeral_noun), #ELSE, # переход к следующему уровню\n",
    "    p_dop_noun2,\n",
    "    D(dict_pronoun_dp)\n",
    ")\n",
    "@debug_pp\n",
    "def p_noun1_ip(s,p): return p_alt(s,p,\n",
    "    seq([ p_numeral, p_noun2 ], r_numeral_noun), #ELSE, # переход к следующему уровню\n",
    "    p_noun2,\n",
    "    D(dict_pronoun_ip)\n",
    ")\n",
    "def r_numeral_noun(num,n):\n",
    "    if num.chis!=n.chis :\n",
    "        warning('не совпадают числа числ. и сущ.:'+str(num)+str(n))\n",
    "    return StNum([\n",
    "        I(quantity=num,            chis=n.chis, rod=n.rod, odush=n.odush ),\n",
    "        I(maindep=n)\n",
    "    ],quantity=num.quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_noun\n",
    "###### p_dop_noun\n",
    "###### p_noun_ip\n",
    "r_noun_and_noun, r_noun_comma_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.103900Z",
     "start_time": "2019-10-15T17:37:35.990894Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun1, W('and'), p_noun ],r_noun_and_noun  ),\n",
    "        seq([ p_noun1, W(',')  , p_noun ],r_noun_comma_noun),\n",
    "                 #ELSE, # переход к следующему уровню\n",
    "                 # идет конфликт с and-ом из глаголов\n",
    "        p_noun1\n",
    "    )\n",
    "@debug_pp\n",
    "def p_dop_noun(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_dop_noun1, W('and'), p_dop_noun ],r_noun_and_noun  ),\n",
    "        seq([ p_dop_noun1, W(',')  , p_dop_noun ],r_noun_comma_noun),\n",
    "                 #ELSE, # переход к следующему уровню\n",
    "                 # идет конфликт с and-ом из глаголов\n",
    "        p_dop_noun1\n",
    "    )\n",
    "@debug_pp\n",
    "def p_noun_ip(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun1_ip, W('and'), p_noun_ip ],r_noun_and_noun  ),\n",
    "        seq([ p_noun1_ip, W(',')  , p_noun_ip ],r_noun_comma_noun),\n",
    "                 #ELSE, # переход к следующему уровню\n",
    "                 # идет конфликт с and-ом из глаголов\n",
    "        p_noun1_ip\n",
    "    )\n",
    "def r_noun_and_noun(sn,a,n):    return StNoun([\n",
    "    I(dep=sn),\n",
    "    I(nodep=S('и',a.attrs)),\n",
    "    I(dep=n)\n",
    "],c='mn', p='ip',o=False,r='m')\n",
    "def r_noun_comma_noun(sn,c,n):    return StNoun([\n",
    "    I(dep=sn),\n",
    "    I(punct=S(',',c.attrs)),\n",
    "    I(dep=n)\n",
    "],c='mn', p='ip',o=False,r='m')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Существительные в разных формах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_noun_dp\n",
    "r_noun_dp, r_TO_noun_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.196906Z",
     "start_time": "2019-10-15T17:37:36.105900Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun_dp(s,p): return p_alt(s,p,\n",
    "    seq([D(dict_pronoun_dp)],r_noun_dp), \n",
    "    seq([ W('to'), p_noun ],r_TO_noun_dp)\n",
    ")\n",
    "def r_noun_dp(_n): return StNoun([\n",
    "    I(maindep=_n,         pad='dp')\n",
    "])\n",
    "\n",
    "def r_TO_noun_dp(_t,_n): return StNoun([\n",
    "    I(maindep=_n,         pad='dp', attrs_from_left=_t.attrs)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_IN_THE_STREET\n",
    "r_NA_X_ULITSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.295911Z",
     "start_time": "2019-10-15T17:37:36.198906Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# на (определенной) улице\n",
    "@debug_pp\n",
    "def pe_IN_THE_STREET(s,p): return p_alt(s,p,\n",
    "    seq([W('in'), W('the'), W('street') ],r_NA_X_ULITSE),\n",
    ")\n",
    "def r_NA_X_ULITSE(v,_a,_U): return StC([\n",
    "    I(nodep=S('на',v.attrs)),\n",
    "    I(nodep=CW('улица',_U),pad='pp')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_IN_adj_STREET\n",
    "r_NA_adj_ULITSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.379916Z",
     "start_time": "2019-10-15T17:37:36.298911Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# на какой-то улице\n",
    "@debug_pp\n",
    "def pe_IN_adj_STREET(s,p): return p_alt(s,p,\n",
    "    pe_IN_THE_STREET,\n",
    "    ELSE,\n",
    "    seq([W('in'), p_adj, W('street') ],r_NA_adj_ULITSE),\n",
    ")\n",
    "def r_NA_adj_ULITSE(v,_a,_U): return StC([\n",
    "    I(nodep=S('на',v.attrs)),\n",
    "    I(nodep = StNoun([\n",
    "        I(dep=_a,\n",
    "            rod='g',\n",
    "            chis='ed',\n",
    "            pad='ip'),\n",
    "        I(maindep=CW('улица',_U))\n",
    "    ]),pad='pp')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_IN_THE_GARDEN\n",
    "r_V_X_SADU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.486922Z",
     "start_time": "2019-10-15T17:37:36.381916Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# на (определенной) улице\n",
    "@debug_pp\n",
    "def pe_IN_THE_GARDEN(s,p): return p_alt(s,p,\n",
    "    seq([W('in'), W('the'), W('garden') ],r_V_X_SADU),\n",
    ")\n",
    "def r_V_X_SADU(v,_a,_U): return StC([\n",
    "    I(nodep=S('в',v.attrs)),\n",
    "    I(nodep=CW('сад',_U),pad='dp')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_IN_adj_GARDEN\n",
    "r_V_adj_SADU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.621930Z",
     "start_time": "2019-10-15T17:37:36.488922Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# на какой-то улице\n",
    "@debug_pp\n",
    "def pe_IN_adj_GARDEN(s,p): return p_alt(s,p,\n",
    "    pe_IN_THE_GARDEN,\n",
    "    ELSE,\n",
    "    seq([W('in'), p_adj, W('garden') ],r_V_adj_SADU),\n",
    ")\n",
    "def r_V_adj_SADU(v,_a,_U): return StC([\n",
    "    I(nodep=S('в',v.attrs)),\n",
    "    I(nodep=_a,\n",
    "        rod='m',\n",
    "        chis='ed',\n",
    "        pad='pp'),\n",
    "    I(nodep=CW('сад',_U),pad='dp')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_where\n",
    "r_V_noun_pp, r_NA_noun_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.729936Z",
     "start_time": "2019-10-15T17:37:36.623930Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# где\n",
    "@debug_pp\n",
    "def p_where(s,p): return p_alt(s,p,\n",
    "    pe_IN_adj_STREET,\n",
    "    pe_IN_adj_GARDEN,\n",
    "    ELSE,\n",
    "    seq([W('in'), p_dop_noun ],r_V_noun_pp),\n",
    "    seq([W('on'), p_dop_noun ],r_NA_noun_pp),\n",
    "    seq([W('under'), p_dop_noun ],r_POD_noun_pp),\n",
    ")\n",
    "def r_V_noun_pp(v,_n): return StC([\n",
    "    I(nodep=S('в',v.attrs)),\n",
    "    I(nodep=_n,  pad='pp'),\n",
    "])\n",
    "def r_NA_noun_pp(v,_n): return StC([\n",
    "    I(nodep=S('на',v.attrs)),\n",
    "    I(nodep=_n,  pad='pp'),\n",
    "])\n",
    "def r_POD_noun_pp(v,_n): return StC([\n",
    "    I(nodep=S('под',v.attrs)),\n",
    "    I(nodep=_n,  pad='tp'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_dop\n",
    "r_X_noun_dp, r_IZ_noun, r_S_noun_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.820941Z",
     "start_time": "2019-10-15T17:37:36.731936Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# одно дополнение\n",
    "@debug_pp\n",
    "def p_dop(s,p): return p_alt(s,p,\n",
    "    seq([W('to'), p_dop_noun ],r_X_noun_dp),\n",
    "    seq([W('from'),p_dop_noun],r_IZ_noun),\n",
    "    seq([W('with'),p_dop_noun],r_S_noun_tp),\n",
    "    p_where\n",
    ")\n",
    "def r_X_noun_dp(x,n): return StNoun([\n",
    "    I(maindep=n,  pad='dp',         attrs_from_left=x.attrs)\n",
    "])\n",
    "def r_IZ_noun(iz,n): return StNoun([\n",
    "    I(nodep=S('из',iz.attrs)),\n",
    "    I(maindep=n,  pad='rp')\n",
    "])\n",
    "def r_S_noun_tp(s,n): return StNoun([\n",
    "    I(nodep=S('с',s.attrs)),\n",
    "    I(maindep=n,  pad='tp')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_dops\n",
    "r_seq_dops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:36.923947Z",
     "start_time": "2019-10-15T17:37:36.822941Z"
    },
    "code_folding": [
     6
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# последовательность дополнений\n",
    "@debug_pp\n",
    "def p_dops(s,p): return p_alt(s,p,\n",
    "    p_dop,\n",
    "    seq([p_dop, p_dops], r_seq_dops)\n",
    ")\n",
    "def r_seq_dops(d1,d2): return StC([\n",
    "    I(nodep=d1),\n",
    "    I(nodep=d2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## have/has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.011952Z",
     "start_time": "2019-10-15T17:37:36.925947Z"
    }
   },
   "outputs": [],
   "source": [
    "px_HAVE_HAS = alt( W('have'), W('has') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_have_question\n",
    "r_have_question, rv_HOW_MANY_noun_HAVE_noun(r_SKOLKO_noun_U_noun, r_SKOLKO_U_noun_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.096957Z",
     "start_time": "2019-10-15T17:37:37.013952Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_have_question(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([px_HAVE_HAS,p_noun_ip,p_noun],r_have_question),\n",
    "        seq([W('how'), W('many'), p_noun, px_HAVE_HAS, p_noun_ip], rv_HOW_MANY_noun_HAVE_noun)\n",
    "    )\n",
    "\n",
    "def r_have_question(_h,_n1,_n2):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1,   pad='rp', npad='n' )# у Него\n",
    "    ]), pull_attrs=1 ),\n",
    "    I(nodep=S('есть',_h.attrs)),\n",
    "    I(nodep=_n2)\n",
    "])\n",
    "def r_SKOLKO_noun_U_noun(how,many,_n1,have,_n2):  return StC([\n",
    "    I(nodep=S('сколько',how.attrs), attrs_from_right=many.attrs),\n",
    "    I(nodep=_n1, pad='rp'),\n",
    "    I(nodep=S('у')),\n",
    "    I(nodep=_n2,   pad='rp', npad='n' )# у Него\n",
    "])\n",
    "def r_SKOLKO_U_noun_noun(how,many,_n1,have,_n2):  return StC([\n",
    "    I(nodep=S('сколько',how.attrs), attrs_from_right=many.attrs),\n",
    "    I(nodep=S('у')),\n",
    "    I(nodep=_n2,   pad='rp', npad='n' ),# у Него\n",
    "    I(nodep=_n1, pad='rp'),\n",
    "])\n",
    "rv_HOW_MANY_noun_HAVE_noun = RuleVars('r_SKOLKO_U_noun_noun',\n",
    "                                      dict_funs(r_SKOLKO_noun_U_noun,r_SKOLKO_U_noun_noun))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_noun_HAVE_noun\n",
    "rv_noun_HAVE_noun(r_U_noun_EST_noun, r_U_noun_noun), r_U_noun_NET_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.179962Z",
     "start_time": "2019-10-15T17:37:37.101957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_noun_HAVE_noun(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun_ip, px_HAVE_HAS,          p_noun ],rv_noun_HAVE_noun),\n",
    "        seq([ p_noun_ip, px_HAVE_HAS, W('no'), p_noun ],r_U_noun_NET_noun)\n",
    "#        seq([ p_noun, p_HAVE_HAS,          p_pronoun_dp ],r_noun_EST_U_noun),\n",
    "#        seq([ p_noun, p_HAVE_HAS, W('no'), p_pronoun_dp ],r_noun_NET_U_noun)\n",
    "    )\n",
    "def r_U_noun_EST_noun(_n1_,_h_,_n2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ]), pull_attrs=1 ),\n",
    "    I(nodep=S('есть',_h_.attrs)),\n",
    "    I(nodep=_n2_)\n",
    "])\n",
    "def r_U_noun_noun(_n1_,_h_,_n2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ]), pull_attrs=1, attrs_from_right = _h_.attrs ),\n",
    "    I(nodep=_n2_)\n",
    "])\n",
    "rv_noun_HAVE_noun = RuleVars('r_U_noun_EST_noun',dict_funs(r_U_noun_noun, r_U_noun_EST_noun))\n",
    "\n",
    "def r_U_noun_NET_noun(_n1_,_h_,_no_,_n2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ]), pull_attrs=1 ),\n",
    "    I(nodep=S('нет',_h_.attrs)),\n",
    "    I(nodep=_n2_,        pad='rp')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_noun_HAVE\n",
    "r_U_noun_EST, r_U_noun_NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.275967Z",
     "start_time": "2019-10-15T17:37:37.189962Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_noun_HAVE(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun_ip, px_HAVE_HAS          ],r_U_noun_EST),\n",
    "        seq([ p_noun_ip, px_HAVE_HAS, alt(W('no'),W('not')) ],r_U_noun_NET)\n",
    "#        seq([ p_noun, p_HAVE_HAS,          p_pronoun_dp ],r_noun_EST_U_noun),\n",
    "#        seq([ p_noun, p_HAVE_HAS, W('no'), p_pronoun_dp ],r_noun_NET_U_noun)\n",
    "    )\n",
    "def r_U_noun_EST(_n1_,_h_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ]), pull_attrs=1 ),\n",
    "    I(nodep=S('есть',_h_.attrs))\n",
    "])\n",
    "\n",
    "def r_U_noun_NET(_n1_,_h_,_no_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ]), pull_attrs=1 ),\n",
    "    I(nodep=S('нет',_h_.attrs))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_HAVE_noun\n",
    "r_IMET_noun_vp, r_NE_IMET_noun_vp, r_IMET, r_NE_IMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.354972Z",
     "start_time": "2019-10-15T17:37:37.279968Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_HAVE_noun(s,p): \n",
    "    return p_alt(s,p,\n",
    "        seq([px_HAVE_HAS,          p_noun], r_IMET_noun_vp),\n",
    "        seq([px_HAVE_HAS, W('no'), p_noun], r_NE_IMET_noun_vp),\n",
    "        seq([px_HAVE_HAS],r_IMET),\n",
    "        seq([px_HAVE_HAS,alt(W('no'),W('not'))],r_NE_IMET)\n",
    "    )\n",
    "def r_NE_IMET_noun_vp(_v,no,_n): return StVerb([\n",
    "    I(nodep=S('не',no.attrs)),\n",
    "    I(maindep=CW('иметь',_v)),\n",
    "    I(vp=_n,   pad='vp')\n",
    "])\n",
    "def r_IMET_noun_vp(_v,_n): return StVerb([\n",
    "    I(maindep=CW('иметь',_v)),\n",
    "    I(vp=_n,   pad='vp')\n",
    "])\n",
    "def r_IMET(_v): return StVerb([\n",
    "    I(maindep=CW('иметь',_v)),\n",
    "])\n",
    "def r_NE_IMET(_v,no): return StVerb([\n",
    "    I(nodep=S('не',no.attrs)),\n",
    "    I(maindep=CW('иметь',_v)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to_be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_noun_TOBE_where\n",
    "re_ETO_X_where, re_TO_X_where, r_noun_X_where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.457978Z",
     "start_time": "2019-10-15T17:37:37.356972Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_noun_TOBE_where(s,p): return p_alt(s,p,\n",
    "    seq([W('this'),p_TOBE,p_where],re_ETO_X_where),\n",
    "    seq([W('that'),p_TOBE,p_where],re_TO_X_where),\n",
    "    ELSE,\n",
    "    seq([p_noun_ip,p_TOBE,p_where],r_noun_X_where)\n",
    ")\n",
    "\n",
    "def r_noun_X_where(_n,x,_w): return StC([\n",
    "    I(nodep=_n),\n",
    "    I(nodep=_w, attrs_from_left=x.attrs)\n",
    "])\n",
    "def re_ETO_X_where(_n,x,_w): return StC([\n",
    "    I(nodep=CW('этот',_n), rod='s'),\n",
    "    I(nodep=_w, attrs_from_left=x.attrs)\n",
    "])\n",
    "def re_TO_X_where(_n,x,_w): return StC([\n",
    "    I(nodep=CW('тот',_n, rod='s')),\n",
    "    I(nodep=_w, attrs_from_left=x.attrs)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_noun_TOBE_where_TOO\n",
    "re_ETO_X_TOJE_where, re_TO_X_TOJE_where, r_noun_X_TOJE_where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.528982Z",
     "start_time": "2019-10-15T17:37:37.459978Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_noun_TOBE_where_TOO(s,p): return p_alt(s,p,\n",
    "    seq([W('this'),p_TOBE,p_where,W('too')],re_ETO_X_TOJE_where),\n",
    "    seq([W('that'),p_TOBE,p_where,W('too')],re_TO_X_TOJE_where),\n",
    "    ELSE,\n",
    "    seq([p_noun_ip,p_TOBE,p_where,W('too')],r_noun_X_TOJE_where)\n",
    ")\n",
    "\n",
    "def r_noun_X_TOJE_where(_n,x,_w,too): return StC([\n",
    "    I(nodep=_n),\n",
    "    I(nodep=S('тоже',too.attrs)),\n",
    "    I(nodep=_w, attrs_from_left=x.attrs)\n",
    "])\n",
    "def re_ETO_X_TOJE_where(_n,x,_w,too): return StC([\n",
    "    I(nodep=CW('этот',_n), rod='s'),\n",
    "    I(nodep=S('тоже',too.attrs)),\n",
    "    I(nodep=_w, attrs_from_left=x.attrs)\n",
    "])\n",
    "def re_TO_X_TOJE_where(_n,x,_w,too): return StC([\n",
    "    I(nodep=CW('тот',_n, rod='s')),\n",
    "    I(nodep=S('тоже',too.attrs)),\n",
    "    I(nodep=_w, attrs_from_left=x.attrs)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_noun_TOBE_noun\n",
    "re_ETO_X_noun, re_TO_X_noun, r_noun_X_noun, r_noun_X_NE_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.615987Z",
     "start_time": "2019-10-15T17:37:37.530982Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_noun_TOBE_noun(s,p): return p_alt(s,p,\n",
    "    seq([W('this'),p_TOBE,p_noun],re_ETO_X_noun),\n",
    "    seq([W('that'),p_TOBE,p_noun],re_TO_X_noun),\n",
    "    ELSE,\n",
    "    seq([p_noun_ip,p_TOBE,p_noun],r_noun_X_noun),\n",
    "    seq([p_noun_ip,p_TOBE,W('not'),p_noun],r_noun_X_NE_noun)\n",
    ")\n",
    "\n",
    "def r_noun_X_noun(_n1,_tobe,_n2): return StC([\n",
    "    I(nodep=_n1),\n",
    "    I(nodep=S('--',_tobe.attrs)),\n",
    "    I(nodep=_n2, rod=_n1.rod)\n",
    "])\n",
    "def r_noun_X_NE_noun(_n1,_tobe,_not,_n2): return StC([\n",
    "    I(nodep=_n1),\n",
    "    I(nodep=S('--',_tobe.attrs)),\n",
    "    I(nodep=S('не',_not.attrs)),\n",
    "    I(nodep=_n2, rod=_n1.rod)\n",
    "])\n",
    "def re_ETO_X_noun(_n1,_tobe,_n2): return StC([\n",
    "    I(nodep=CW('этот',_n1), rod='s'),\n",
    "    I(nodep=_n2, attrs_from_left = _tobe.attrs)\n",
    "])\n",
    "def re_TO_X_noun(_n1,_tobe,_n2): return StC([\n",
    "    I(nodep=CW('тот',_n1), rod='s'),\n",
    "    I(nodep=_n2, attrs_from_left = _tobe.attrs)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### pe_noun_TOBE_noun_TOO\n",
    "re_ETO_X_TOJE_noun, re_TO_X_TOJE_noun, r_noun_X_TOJE_noun, r_noun_X_TOJE_NE_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.696991Z",
     "start_time": "2019-10-15T17:37:37.618987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_noun_TOBE_noun_TOO(s,p): return p_alt(s,p,\n",
    "    seq([W('this'),p_TOBE,p_noun,W('too')],re_ETO_X_TOJE_noun),\n",
    "    seq([W('that'),p_TOBE,p_noun,W('too')],re_TO_X_TOJE_noun),\n",
    "    ELSE,\n",
    "    seq([p_noun_ip,p_TOBE,p_noun,W('too')],r_noun_X_TOJE_noun),\n",
    "    seq([p_noun_ip,p_TOBE,W('not'),p_noun,W('too')],r_noun_X_TOJE_NE_noun)\n",
    ")\n",
    "\n",
    "def r_noun_X_TOJE_noun(_n1,_tobe,_n2,_too): return StC([\n",
    "    I(nodep=_n1),\n",
    "    I(nodep=S('--',_tobe.attrs)),\n",
    "    I(nodep=S('тоже',_too.attrs)),\n",
    "    I(nodep=_n2, rod=_n1.rod)\n",
    "])\n",
    "def r_noun_X_TOJE_NE_noun(_n1,_tobe,_not,_n2,_too): return StC([\n",
    "    I(nodep=_n1),\n",
    "    I(nodep=S('--',_tobe.attrs)),\n",
    "    I(nodep=S('тоже',_too.attrs)),\n",
    "    I(nodep=S('не',_not.attrs)),\n",
    "    I(nodep=_n2, rod=_n1.rod)\n",
    "])\n",
    "def re_ETO_X_TOJE_noun(_n1,_tobe,_n2,_too): return StC([\n",
    "    I(nodep=CW('этот',_n1), rod='s'),\n",
    "    I(nodep=S('тоже',_too.attrs)),\n",
    "    I(nodep=_n2, attrs_from_left = _tobe.attrs)\n",
    "])\n",
    "def re_TO_X_TOJE_noun(_n1,_tobe,_n2,_too): return StC([\n",
    "    I(nodep=CW('тот',_n1), rod='s'),\n",
    "    I(nodep=S('тоже',_too.attrs)),\n",
    "    I(nodep=_n2, attrs_from_left = _tobe.attrs)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_TOBE\n",
    "r_EST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.762995Z",
     "start_time": "2019-10-15T17:37:37.698991Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_TOBE(s,p): return p_alt(s,p,\n",
    "    seq([W('be')],r_EST),\n",
    "    seq([W('am')],r_EST),\n",
    "    seq([W('is')],r_EST),\n",
    "    seq([W('are')],r_EST)\n",
    ")\n",
    "def r_EST(_v): return StVerb([\n",
    "    I(maindep=CW('есть (быть)',_v)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_TOBE_noun\n",
    "rv_TOBE_noun(r_EST_noun_ip, r_JAVLYATSA_noun_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.854000Z",
     "start_time": "2019-10-15T17:37:37.765995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_TOBE_noun(s,p): return p_alt(s,p,\n",
    "    seq([p_TOBE, p_noun], rv_TOBE_noun),\n",
    "#    seq([p_tobe, W('no'), alt(p_noun,D(dict_pronoun_dp))], r_NE_IMET_noun_vp),\n",
    "    p_TOBE\n",
    ")\n",
    "def r_EST_noun_ip(_v,_n): return StVerb([\n",
    "    I(maindep=CW('есть (быть)',_v)),\n",
    "    I(ip=_n,   pad='ip')\n",
    "])\n",
    "def r_JAVLYATSA_noun_tp(_v,_n): return StVerb([\n",
    "    I(maindep=CW('являться',_v)),\n",
    "    I(tp=_n,   pad='tp')\n",
    "])\n",
    "rv_TOBE_noun = RuleVars('r_EST_noun_ip',dict_funs(r_EST_noun_ip, r_JAVLYATSA_noun_tp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### p_tobe_question\n",
    "r_GDE_noun_ip, r_noun_noun_question, r_noun_question, r_noun_adj_question, r_noun_where_TOO_question, r_CHTO_ETO, r_CHTO_TAKOE_noun_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:37.942005Z",
     "start_time": "2019-10-15T17:37:37.856000Z"
    }
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_tobe_question(s,p): return p_alt(s,p,\n",
    "    seq([p_TOBE,p_noun_ip],r_noun_question),\n",
    "    seq([p_TOBE,p_noun_ip,p_adj],r_noun_adj_question),\n",
    "    seq([W('what'),p_TOBE,W('this')],r_CHTO_ETO),\n",
    "    ELSE,\n",
    "    seq([W('what'),p_TOBE,p_noun_ip],r_CHTO_TAKOE_noun_ip),\n",
    "    seq([W('where'),p_TOBE,p_noun_ip],r_GDE_noun_ip),\n",
    "    seq([W('what'),W('colour'),p_TOBE,p_noun_ip],r_KAKOGO_TSVETA_noun_ip),\n",
    "    seq([p_TOBE,p_noun_ip,p_noun],r_noun_noun_question),\n",
    "    seq([p_TOBE,p_noun_ip,p_where,W('too')],r_noun_where_TOO_question)\n",
    ")\n",
    "def r_CHTO_ETO(what,_v,this): return StC([\n",
    "    I(nodep=S('что',what.attrs), attrs_from_right=_v.attrs),\n",
    "    I(nodep=S('это',this.attrs))\n",
    "])\n",
    "def r_CHTO_TAKOE_noun_ip(what,_v,_n): return StC([\n",
    "    I(nodep=S('что',what.attrs)),\n",
    "    I(nodep=S('такое',what.attrs), attrs_from_right=_v.attrs),\n",
    "    I(nodep=_n, pad='ip')\n",
    "])\n",
    "def r_GDE_noun_ip(where,_v,_n): return StC([\n",
    "    I(nodep=S('где',where.attrs), attrs_from_right=_v.attrs),\n",
    "    I(nodep=_n, pad='ip')\n",
    "])\n",
    "def r_KAKOGO_TSVETA_noun_ip(what,color,_v,_n): return StC([\n",
    "    I(nodep=S('какого',what.attrs)),\n",
    "    I(nodep=S('цвета',color.attrs), attrs_from_right=_v.attrs),\n",
    "    I(nodep=_n, pad='ip')\n",
    "])\n",
    "def r_noun_noun_question(_v,_n1,_n2): return StC([\n",
    "    I(nodep=_n1, pad='ip'),\n",
    "    I(nodep=S('--')),\n",
    "    I(nodep=_n2, pad='ip')\n",
    "])\n",
    "def r_noun_adj_question(_v,_n,_a): return StC([\n",
    "    I(nodep=_n, pad='ip'),\n",
    "    I(nodep=S('--')),\n",
    "    I(nodep=_a, pad='ip', rod=_n.rod)\n",
    "])\n",
    "def r_noun_question(_v,_n): return StC([\n",
    "    I(nodep=_n, pad='ip'),\n",
    "])\n",
    "def r_noun_where_TOO_question(_v,_n,_wh,too): return StC([\n",
    "    I(nodep=_n, pad='ip'),\n",
    "    I(nodep=S('тоже', too.attrs)),\n",
    "    I(nodep=_wh),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глагол с дополнениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### разделяемые правила\n",
    "r_verb_noun_vp, r_verb_noun_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.022010Z",
     "start_time": "2019-10-15T17:37:37.944005Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# разделяемые правила\n",
    "def r_verb_noun_vp(_v,_p): return StVerb([\n",
    "    I(maindep= _v),\n",
    "    I(vp=_p,   pad='vp')\n",
    "])\n",
    "def r_verb_noun_dp(_v,_p): return StVerb([\n",
    "    I(maindep= _v),\n",
    "    I(dp=_p,   pad='dp')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb3_komu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.107015Z",
     "start_time": "2019-10-15T17:37:38.024010Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# сделать кому-то\n",
    "@debug_pp\n",
    "def p_verb3_komu(s,p): return p_alt(s,p,\n",
    "    seq([D(dict_verb_komu), p_noun_dp], r_verb_noun_dp),\n",
    "    D(dict_verb_komu)\n",
    ")\n",
    "# r_verb_noun_dp - разделяемое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb3_komu_chto\n",
    "r_verb_c_phrase, r_verb_q_text, r_verb_c_q_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.188019Z",
     "start_time": "2019-10-15T17:37:38.109015Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# сделать кому-то что-то\n",
    "@debug_pp\n",
    "def p_verb3_komu_chto(s,p): return p_alt(s,p,\n",
    "    seq([p_verb3_komu,                D(dict_pronoun_dp)], r_verb_noun_dp),\n",
    "    ELSE,\n",
    "    seq([ p_verb3_komu,                 p_noun        ], r_verb_noun_vp),\n",
    "    seq([ p_verb3_komu, W(':'),         p_phrase      ], r_verb_c_phrase),\n",
    "    seq([ p_verb3_komu,         W('\"'), p_text, W('\"')], r_verb_q_text),\n",
    "    seq([ p_verb3_komu, W(':'), W('\"'), p_text, W('\"')], r_verb_c_q_text), \n",
    "    p_verb3_komu\n",
    ")\n",
    "# r_verb_noun_vp - разделяемое\n",
    "# r_verb_noun_dp - разделяемое\n",
    "def r_verb_c_phrase(_v,c,_p): return StVerb([\n",
    "    I(maindep=_v),\n",
    "    I(punct=c),\n",
    "    I(nodep=_p)\n",
    "])\n",
    "def r_verb_q_text(_v,q1,_p,q2): return StVerb([\n",
    "    I(maindep=_v),\n",
    "    I(punct=q1, add_changers={ch_open}),\n",
    "    I(nodep=_p),\n",
    "    I(punct=q2),\n",
    "])\n",
    "def r_verb_c_q_text(_v,c,q1,_p,q2): return StVerb([\n",
    "    I(maindep=_v),\n",
    "    I(punct=c),\n",
    "    I(punct=q1, add_changers={ch_open}),\n",
    "    I(nodep=_p),\n",
    "    I(punct=q2),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb2\n",
    "re_verb_OT_noun_DO_noun, r_verb_dops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.283025Z",
     "start_time": "2019-10-15T17:37:38.190020Z"
    },
    "code_folding": [
     13
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# глагол с дополнением\n",
    "@debug_pp\n",
    "def p_verb2(s,p): return p_alt(s,p,\n",
    "    seq([D(dict_verb_simple),W('from'),p_noun,W('to'), p_noun],re_verb_OT_noun_DO_noun),\n",
    "    ELSE,\n",
    "    seq([D(dict_verb_simple), p_dops],r_verb_dops),\n",
    "    D(dict_verb_simple)\n",
    ")\n",
    "\n",
    "def r_verb_dops(_v,_d): return StVerb([\n",
    "    I(maindep=_v),\n",
    "    I(nodep=_d)\n",
    "])\n",
    "def re_verb_OT_noun_DO_noun(_v,ot,_n1,do,_n2): return StVerb([\n",
    "    I(maindep=_v),\n",
    "    I(nodep=S('от',ot.attrs)),\n",
    "    I(nodep=_n1,  pad='rp'),\n",
    "    I(nodep=S('до',do.attrs)),\n",
    "    I(nodep=_n2,  pad='rp')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb3_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.378030Z",
     "start_time": "2019-10-15T17:37:38.291025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# сделать что-то\n",
    "@debug_pp\n",
    "def p_verb3_simple(s,p): return p_alt(s,p,\n",
    "    seq([p_verb2, p_noun], r_verb_noun_vp),\n",
    "    p_verb2\n",
    ")\n",
    "# r_verb_noun_vp - разделяемое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.465035Z",
     "start_time": "2019-10-15T17:37:38.381030Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# сделать (кому-то что-то)\n",
    "@debug_pp\n",
    "def p_verb3_1(s,p): return p_alt(s,p,\n",
    "    p_verb3_simple,\n",
    "    p_verb3_komu_chto,\n",
    "    p_HAVE_noun,\n",
    "    p_TOBE_noun,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb3\n",
    "r_CAN_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.557041Z",
     "start_time": "2019-10-15T17:37:38.467035Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# могу сделать\n",
    "@debug_pp\n",
    "def p_verb3(s,p): return p_alt(s,p,\n",
    "    seq([W('can'), p_verb3_1],r_CAN_verb),\n",
    "    p_verb3_1\n",
    ")\n",
    "def r_CAN_verb(c,v): return StVerb([\n",
    "    I(maindep=CW('мочь',c)),\n",
    "    I(nodep=v,   form='neopr')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глагол(ы) с подлежащим, или другой формы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_noun_verb1\n",
    "r_noun_verb, r_noun_TOZHE_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.666047Z",
     "start_time": "2019-10-15T17:37:38.559041Z"
    },
    "code_folding": [
     10
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# некто делает\n",
    "@debug_pp\n",
    "def p_noun_verb1(s,p): return p_alt(s,p,\n",
    "    pe_noun_HAVE_noun,\n",
    "    pe_noun_HAVE,\n",
    "    pe_noun_TOBE_noun,\n",
    "    pe_noun_TOBE_noun_TOO,\n",
    "ELSE,\n",
    "    pe_noun_TOBE_where,\n",
    "    pe_noun_TOBE_where_TOO,\n",
    "    seq([p_noun_ip,p_TOBE,W('not'),p_noun],r_noun_X_NE_noun),\n",
    "    seq([ p_noun_ip , p_verb3 ],r_noun_verb),\n",
    "    seq([ p_noun_ip, p_verb3, W('too') ],r_noun_TOZHE_verb), #ELSE, # переход к следующему уровню\n",
    ")\n",
    "\n",
    "def r_noun_verb(n,v): return StVerb([\n",
    "    I(ip=n),\n",
    "    I(main=v,   form='nast', pers=n.pers, chis=n.chis, rod=n.rod)\n",
    "])\n",
    "def r_noun_TOZHE_verb(_n, _v, _t): return StVerb([\n",
    "    I(ip=_n),\n",
    "    I(nodep=S('тоже',_t.attrs)),\n",
    "    I(main=_v,   form='nast', pers=_n.pers, chis=_n.chis, rod=_n.rod)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb1\n",
    "r_to_verb, rv_rule_povel_verb(r_povel_verb_ed, r_povel_verb_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.762052Z",
     "start_time": "2019-10-15T17:37:38.668047Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# некто делает/ делать/ делай\n",
    "@debug_pp\n",
    "def p_verb1(s,p): return p_alt(s,p,\n",
    "    p_noun_verb1,\n",
    "    seq([ W('to'), p_verb3 ],r_to_verb),   #ELSE, # переход к следующему уровню\n",
    "    seq([ p_verb3 ],rv_rule_povel_verb)\n",
    ")\n",
    "def r_to_verb(_t,_v): return StVerb([\n",
    "    I(maindep=_v,         form='neopr', attrs_from_left=_t.attrs)\n",
    "])\n",
    "\n",
    "def r_povel_verb_ed(_v): return StVerb([\n",
    "    I(maindep=_v, asp='sov', form='povel',chis='ed') #\n",
    "])\n",
    "def r_povel_verb_mn(_v): return StVerb([\n",
    "    I(maindep=_v, asp='sov', form='povel',chis='mn') # asp='sov',\n",
    "])\n",
    "rv_rule_povel_verb = RuleVars('r_povel_verb_ed',dict_funs(r_povel_verb_ed,r_povel_verb_mn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_verb\n",
    "r_verb_NO_verb, r_verb_c_verb, r_verb_I_verb, re_U_noun_EST_noun_C_noun_I_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:38.972064Z",
     "start_time": "2019-10-15T17:37:38.764052Z"
    },
    "code_folding": [
     10,
     17
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# сделать одно и/но сделать сдругое\n",
    "@debug_pp\n",
    "def p_verb(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun_ip, px_HAVE_HAS, p_noun1, W(',')  , p_noun,  W('and'), p_verb1 ],re_U_noun_EST_noun_C_noun_I_verb),\n",
    "    ELSE,\n",
    "    seq([ p_verb1, W(','), p_verb1 ]          ,r_verb_c_verb),   \n",
    "    seq([ p_verb1, W(','), W('but'), p_verb1 ],r_verb_NO_verb),   \n",
    "    seq([ p_verb1, W('and'), p_verb1 ]        ,r_verb_I_verb),\n",
    "    #ELSE, # переход к следующему уровню\n",
    "    p_verb1\n",
    ")\n",
    "\n",
    "def r_verb_NO_verb(_v1_,_c_,_but_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=_c_),\n",
    "    I(nodep=S('но',_c_.attrs)),\n",
    "    I(nodep=_v2_)\n",
    "])\n",
    "\n",
    "def r_verb_c_verb(_v1_,_c_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=_c_),\n",
    "    I(nodep=_v2_)\n",
    "])\n",
    "\n",
    "def r_verb_I_verb(_v1_,_i_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=S('и',_i_.attrs)),\n",
    "    I(nodep=_v2_)\n",
    "])\n",
    "\n",
    "def re_U_noun_EST_noun_C_noun_I_verb(_n1_,_h_,sn,c,n,_i_,_v2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=StC([\n",
    "            I(nodep=S('у')),\n",
    "            I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "        ]), pull_attrs=1 ),\n",
    "        I(nodep=S('есть',_h_.attrs)),\n",
    "        I(nodep=StNoun([\n",
    "            I(dep=sn),\n",
    "            I(punct=S(',',c.attrs)),\n",
    "            I(dep=n)\n",
    "        ],c='mn', p='ip',o=False,r='m'))\n",
    "    ])),\n",
    "    I(nodep=S('и',_i_.attrs)),\n",
    "    I(nodep=_v2_)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фразы, предложения, текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_phrase\n",
    "r_DA_ETO_TAK, r_NET_ETO_NE_TAK, r_DA_COMMA_verb, r_NET_COMMA_verb, r_noun_COMMA_verb, r_SPASIBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:39.189077Z",
     "start_time": "2019-10-15T17:37:38.974064Z"
    },
    "code_folding": [
     14,
     20,
     26
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_phrase(s,p): \n",
    "    return p_alt(s,p,\n",
    "        seq([W('yes'),W(','),D(dict_pronoun_ip),p_TOBE],r_DA_ETO_TAK),\n",
    "        ELSE,\n",
    "        seq([W('no'),W(','),D(dict_pronoun_ip),p_TOBE,W('not')],r_NET_ETO_NE_TAK),\n",
    "        p_verb,    #ELSE,\n",
    "        p_noun_ip,    #ELSE,\n",
    "        p_noun_dp, #ELSE,\n",
    "        p_dop,\n",
    "        D(dict_other),\n",
    "        seq([W('yes'),W(','),p_verb],r_DA_COMMA_verb),\n",
    "        seq([W('no') ,W(','),p_verb],r_NET_COMMA_verb),\n",
    "        seq([p_noun  ,W(','),p_verb],r_noun_COMMA_verb),\n",
    "        seq([W('thank'),W('you')],r_SPASIBO),\n",
    "    )\n",
    "\n",
    "def r_SPASIBO(th,you):  return S('спасибо',th.attrs)\n",
    "\n",
    "def r_DA_ETO_TAK(yes,comma,_pn,_be):    return StC([\n",
    "    I(nodep=S('да',yes.attrs)),\n",
    "    I(nodep=comma),\n",
    "    I(nodep=S('это',_pn.attrs)),\n",
    "    I(nodep=S('так',_be.attrs))\n",
    "])\n",
    "\n",
    "def r_NET_ETO_NE_TAK(no,comma,_pn,_be,_not):    return StC([\n",
    "    I(nodep=S('нет',no.attrs)),\n",
    "    I(nodep=comma),\n",
    "    I(nodep=S('это',_pn.attrs)),\n",
    "    I(nodep=S('не',_not.attrs)),\n",
    "    I(nodep=S('так',_be.attrs))\n",
    "])\n",
    "\n",
    "def r_DA_COMMA_verb(yes,comma,_v):    return StC([\n",
    "    I(nodep=S('да',yes.attrs)),\n",
    "    I(nodep=comma),\n",
    "    I(nodep=_v)\n",
    "])\n",
    "\n",
    "def r_NET_COMMA_verb(no,comma,_v):    return StC([\n",
    "    I(nodep=S('нет',no.attrs)),\n",
    "    I(nodep=comma),\n",
    "    I(nodep=_v)\n",
    "])\n",
    "\n",
    "def r_noun_COMMA_verb(_n,comma,_v):    return StC([\n",
    "    # обращение\n",
    "    I(nodep=_n),\n",
    "    I(nodep=comma),\n",
    "    I(nodep=_v)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### p_question_phrase\n",
    "r_noun_COMMA_tobe_question, r_have_question_COMMA_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:39.391088Z",
     "start_time": "2019-10-15T17:37:39.192077Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_question_phrase(s,p): return p_alt(s,p,\n",
    "    seq([alt(p_tobe_question,p_have_question),W(','),p_noun_ip],r_tobehave_question_COMMA_noun),\n",
    "    ELSE,\n",
    "    p_have_question,\n",
    "    p_tobe_question,\n",
    "    seq([p_noun_ip,W(','),alt(p_tobe_question,p_have_question)],r_noun_COMMA_tobehave_question)\n",
    ")\n",
    "def r_noun_COMMA_tobehave_question(_n,comma,_q): return StC([\n",
    "    I(nodep=_n),\n",
    "    I(nodep=comma),\n",
    "    I(nodep=_q)\n",
    "])\n",
    "def r_tobehave_question_COMMA_noun(_q,comma,_n): return StC([\n",
    "    I(nodep=_q),\n",
    "    I(nodep=comma),\n",
    "    I(nodep=_n)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:39.582099Z",
     "start_time": "2019-10-15T17:37:39.393088Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_proper={}# имена собственные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:39.675105Z",
     "start_time": "2019-10-15T17:37:39.584099Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_sentence(s,p):\n",
    "    first_capital = s[p]=='I' or ch_title in s[p].attrs.changers\n",
    "    def r_sentence(ph,d):\n",
    "        rez=StC([I(nodep=ph),I(punct=d)])\n",
    "        if first_capital: rez.attrs.changers|={ch_sentence}\n",
    "        rez.attrs.pre = prefix + rez.attrs.pre\n",
    "        rez.attrs.changers|={ch_prefix}\n",
    "        return rez\n",
    "    restore_title=False\n",
    "    if ch_title in s[p].attrs.changers and s[p] not in dict_proper:\n",
    "        s[p].attrs.changers-={ch_title}\n",
    "        s[p].attrs.changers|={ch_anti_sentence}# хак, реализованный в SAttrs.join()\n",
    "        restore_title=True\n",
    "    prefix = s[p].attrs.pre\n",
    "    s[p].attrs.changers |= {ch_anti_prefix}\n",
    "    try:\n",
    "        rezs=p_alt(s,p,\n",
    "            seq([p_phrase,alt(W('.'),W('!'),W(';'))],r_sentence),\n",
    "            seq([p_question_phrase,W('?')],r_sentence)\n",
    "        )\n",
    "    finally:# не работает, т.к. всё закешировалось\n",
    "        if restore_title:\n",
    "            s[p].attrs.changers|={ch_title}\n",
    "            s[p].attrs.changers-={ch_anti_sentence}\n",
    "        s[p].attrs.pre = prefix\n",
    "    return rezs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### p_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:39.763110Z",
     "start_time": "2019-10-15T17:37:39.677105Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_DEBUGGING = False\n",
    "\n",
    "import bisect\n",
    "\n",
    "def context_fetch_1(s,sentence_points,first,next_,default_variants):\n",
    "    '''преобразует узел next_ в соотетствии с контекстом first\n",
    "\n",
    "    first - указатель на первый узел\n",
    "    next_ - указатель на текущий узел'''\n",
    "    #global CONTEXT_DEBUGGING\n",
    "\n",
    "    def current_rule(rule_group):\n",
    "        '''превращает rule_group в строку - для отладки'''\n",
    "        return '<'+str(id(rule_group))+'>'+\\\n",
    "            str(rule_group.default)+\\\n",
    "            '('+repr_rule(rule_group.vars[rule_group.default])+')'\n",
    "\n",
    "    def update_cache(oldrez,newrez):\n",
    "        '''в кэше oldrez заменяет на newrez'''\n",
    "        if hasattr(oldrez.parse_info,'patterns'):\n",
    "            for pat in oldrez.parse_info.patterns:\n",
    "                if callable(pat):\n",
    "                    cache = parse_system.global_cache\n",
    "                    fn = (oldrez.parse_info.p_start,pat.__name__)\n",
    "                    if fn in cache:\n",
    "                        yes = False\n",
    "                        for i in range(len(cache[fn])):\n",
    "                            if cache[fn][i][1] is oldrez:\n",
    "                                if yes: raise TextError('в кэше дублируется результат')\n",
    "                                yes = True\n",
    "                                cache[fn][i] = (cache[fn][i][0],newrez,cache[fn][i][2])\n",
    "                        if not yes:  raise TextError('в кэше не найден результат')\n",
    "\n",
    "    if first is next_: # дошли до контекстного узла\n",
    "        assert first.context_info.context, first\n",
    "        rule_group = first.context_info.context\n",
    "        # находим номер текущего предложения\n",
    "        ns = bisect.bisect_right(sentence_points,first.context_info.pos)-1\n",
    "        if CONTEXT_DEBUGGING: print('на входе',current_rule(rule_group))\n",
    "        # выбираем правило\n",
    "\n",
    "    # ----------\n",
    "        def tmp_rez_checker(rez):\n",
    "            assert isinstance(rez,classes.Struct) or type(rez)==S or type(rez)==str, (type(rez),rez)\n",
    "            return rez\n",
    "\n",
    "        old_checker = parse_system.rez_checker\n",
    "        parse_system.rez_checker = tmp_rez_checker\n",
    "        old_context_enabled = parse_system.ContextInfo.enabled\n",
    "        parse_system.ContextInfo.enabled = False\n",
    "        try:\n",
    "            # по всем селекторам\n",
    "            for start, stop, p_selector in rule_group.selectors:\n",
    "                if ns+start<0 or ns+stop>len(sentence_points):\n",
    "                    continue\n",
    "                # запускаем с нужной позиции\n",
    "                tmp = p_selector(s,sentence_points[ns+start])\n",
    "                # проверяем позицию всех результатов\n",
    "                assert all([p1==(\n",
    "                    len(s) if ns+stop==len(sentence_points) else sentence_points[ns+stop]\n",
    "                    ) for p1,r1 in tmp])\n",
    "                # отбрасываем None, если результатов нет, идем дальше\n",
    "                tmp = [(p1,r1) for p1,r1 in tmp if r1!=None]\n",
    "                # берем первый результат\n",
    "                if len(tmp):\n",
    "                    if CONTEXT_DEBUGGING and len(tmp)>1: \n",
    "                        print('больше одного варианта контекста')\n",
    "                    rez = tmp[0][1]\n",
    "                    break\n",
    "            else:\n",
    "                if CONTEXT_DEBUGGING: print('выбираем вариант по умолчанию')\n",
    "                rez = rule_group.default\n",
    "        finally:\n",
    "            parse_system.rez_checker = old_checker\n",
    "            parse_system.ContextInfo.enabled = old_context_enabled\n",
    "        if CONTEXT_DEBUGGING: \n",
    "            print('выбрали ',rez)\n",
    "            \n",
    "        #  если строка - запоминаем его, получаем результат\n",
    "        if type(rez)==str:\n",
    "            if not id(rule_group) in default_variants:\n",
    "                default_variants[id(rule_group)] = (rule_group,rule_group.default)\n",
    "            rule_group.select(rez)\n",
    "            if CONTEXT_DEBUGGING: print('selected',id(rule_group),rez)\n",
    "            rez = rule_group.vars[rez]\n",
    "        # если есть аргументы - применяем его и получаем результат\n",
    "        if first.context_info.args:\n",
    "            newrez = rez(*first.context_info.args)\n",
    "        else:\n",
    "            newrez = deepcopy(rez)\n",
    "        # подготавливаем и возвращаем результат\n",
    "        rule_group = copy(rule_group) # для parse_info\n",
    "        assert len(first.context_info.first_context)==0\n",
    "        newrez.parse_info = copy(first.parse_info)\n",
    "        if ParseInfo.enabled:\n",
    "            newrez.parse_info.rule_group = rule_group\n",
    "        update_cache(first,newrez)\n",
    "        return rez_checker(newrez)\n",
    "    # ----------\n",
    "        go_break = False\n",
    "        for k in range(1,len(rule_group)): # по всем правилам\n",
    "            j = 0\n",
    "            for n,test in rule_group[k][1]: # по всем тестам данного правила\n",
    "                if ns+n>=0 and test(s,first.context_info.pos,sentence_points[ns+n]):\n",
    "                    tmp = rule_group[0]\n",
    "                    rule_group[0] = k\n",
    "                    if CONTEXT_DEBUGGING: print('set',id(rule_group),k)\n",
    "                    if not id(rule_group) in default_variants:\n",
    "                        default_variants[id(rule_group)] = (rule_group,tmp)\n",
    "                    old_rule_group = rule_group\n",
    "                    rule_group = copy(rule_group) # для parse_info\n",
    "                    if CONTEXT_DEBUGGING:\n",
    "                        print('at',first.context_info.pos,\n",
    "                              'найдено правило',current_rule(old_rule_group),#current_rule(rule_group),\n",
    "                              'по тесту',j,'('+str(sentence_points[ns+n])+')')\n",
    "                    go_break = True\n",
    "                    break\n",
    "                j+=1\n",
    "            if go_break: break\n",
    "        else:\n",
    "            if CONTEXT_DEBUGGING:\n",
    "                print('at',first.context_info.pos,\n",
    "                      'используем правило',current_rule(rule_group),\n",
    "                      'т.к. ни один вариант не подходит')\n",
    "        rule = rule_group[rule_group[0]][0]\n",
    "        #if CONTEXT_DEBUGGING: print('итого',current_rule(rule_group))\n",
    "        # применяем правило\n",
    "        if first.context_info.args:\n",
    "            newrez = rule(*args)\n",
    "        else:\n",
    "            newrez = deepcopy(rule)\n",
    "        assert len(first.context_info.first_context)==0\n",
    "        newrez.parse_info = copy(first.parse_info)\n",
    "        if ParseInfo.enabled:\n",
    "            newrez.parse_info.rule_group = rule_group\n",
    "        update_cache(first,newrez)\n",
    "        return newrez\n",
    "\n",
    "    else: #шаг рекурсии\n",
    "        first_context = next_.context_info.first_context\n",
    "        for i in range(len(first_context)):\n",
    "            if first_context[i][0]==first: break\n",
    "        else: raise TextError('обрыв пути к контексту')\n",
    "        n = first_context[i][1]\n",
    "        del first_context[i]\n",
    "        next_.context_info.args[n] = \\\n",
    "            context_fetch_1(s,sentence_points,first,next_.context_info.args[n],default_variants)\n",
    "        newrez = next_.context_info.rule(*next_.context_info.args)\n",
    "        newrez.context_info = next_.context_info\n",
    "        if ParseInfo.enabled:\n",
    "            newrez.parse_info = next_.parse_info\n",
    "        update_cache(next_,newrez)\n",
    "        return rez_checker(newrez)\n",
    "\n",
    "def context_fetch(s,sentence_points,rez,default_variants):\n",
    "    '''преобразует узел rez в соотетствии со всеми контекстами, которые указаны в узле'''\n",
    "    # global parse_system.rez_checker\n",
    "    while len(rez.context_info.first_context): # по всем контекстам\n",
    "        # ищем независимый контекстный узел\n",
    "        for first ,n in rez.context_info.first_context:\n",
    "            if len(first.context_info.first_context)==0:\n",
    "                break\n",
    "        else:\n",
    "            raise TextError('не могу выбрать подходящий контекстный узел',rez.context_info.first_context)\n",
    "        rez = context_fetch_1(s,sentence_points,first,rez,default_variants)\n",
    "    return rez\n",
    "\n",
    "\n",
    "@debug_pp\n",
    "def p_text(s,p):\n",
    "    '''или последовательность предложений или 1 фраза\n",
    "    p_text::= p_sentence* | p_phrase\n",
    "    '''\n",
    "    default_variants = {} # сюда замыкается context_fetch_1\n",
    "\n",
    "    # p_text(s,p):\n",
    "    rez=[]\n",
    "    sentence_points = []\n",
    "    pie = ParseInfo.enabled\n",
    "    ParseInfo.enabled = True\n",
    "    try:\n",
    "        while p<len(s):\n",
    "            sentence_points.append(p)\n",
    "            rezs=maxlen_filter(p_sentence(s,p))\n",
    "            if len(rezs)==0: break\n",
    "            p1,r1=rezs[0] # отбрасываем остальные результаты\n",
    "            p=p1\n",
    "            rez.append(r1)\n",
    "\n",
    "        if len(rez)>0:\n",
    "            global CONTEXT_DEBUGGING\n",
    "            if CONTEXT_DEBUGGING:\n",
    "                print('--- text start ---')\n",
    "                for isp in range(len(sentence_points)-1):\n",
    "                    sp = sentence_points[isp]\n",
    "                    nsp =sentence_points[isp+1]\n",
    "                    print(sp,':',SAttrs().join(s[sp:nsp]))\n",
    "                sp = sentence_points[-1]\n",
    "                print(sp,':',SAttrs().join(s[sp:]))\n",
    "                print('--- text end ---')\n",
    "        #    rezs2 =  [(p,StC([ I(nodep=r1) for r1 in rez ]))]\n",
    "            rezs2 =  [(p,StC([\n",
    "                I(nodep=context_fetch(s,sentence_points,r1,default_variants)) for r1 in rez\n",
    "            ]))]\n",
    "        else:\n",
    "            rez = maxlen_filter(alt(p_phrase,p_question_phrase)(s,p))\n",
    "        #    rezs2 = [] if len(rez)==0 else [(rez[0][0],rez[0][1])]\n",
    "            rezs2 = [] if len(rez)==0 else \\\n",
    "                [(rez[0][0],context_fetch(s,sentence_points,rez[0][1],default_variants))]\n",
    "    finally:\n",
    "        ParseInfo.enabled = pie\n",
    "        for idd,(r,n) in default_variants.items():\n",
    "            #print(k)\n",
    "            r.select(n)\n",
    "    return rezs2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:39.911118Z",
     "start_time": "2019-10-15T17:37:39.771110Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def maxlen_filter(rezs):\n",
    "    '''находит самые длинные результаты, а остальные отбрасывает\n",
    "    \n",
    "    если самых длинных несколько - warning\n",
    "    '''\n",
    "    #rezs=patt(s,p)\n",
    "    m=0 # самая длинная длина\n",
    "    im=set() # множество номеров результатаов с самой длинной длиной\n",
    "    for i in range(len(rezs)):\n",
    "        if rezs[i][0]>m:\n",
    "            m=rezs[i][0]\n",
    "            im={i}\n",
    "        elif rezs[i][0]==m:\n",
    "            im.add(i)\n",
    "    long_rezs= [rezs[i] for i in im]\n",
    "    if len(long_rezs)>1:\n",
    "        #print(p,m,s[p:m],SAttrs().join(s))\n",
    "        warning('multiple results:\\n'+\n",
    "            #SAttrs().join(s[p:m])+'\\n'+\n",
    "            '\\n'.join(r.tostr() for void,r in long_rezs)\n",
    "        )\n",
    "            \n",
    "    return [] if len(long_rezs)==0 else long_rezs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Контекстные паттерны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:40.054126Z",
     "start_time": "2019-10-15T17:37:39.913118Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rc_collect_all(*args):\n",
    "    return StC([\n",
    "            I(nodep=r1) for r1 in args\n",
    "        ])\n",
    "def rc_10_5(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    return x5\n",
    "def rc_10_4(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10):\n",
    "    return x4\n",
    "def rc_9_4(x1,x2,x3,x4,x5,x6,x7,x8,x9):\n",
    "    return x4\n",
    "def rc_9_3(x1,x2,x3,x4,x5,x6,x7,x8,x9):\n",
    "    return x3\n",
    "def rc_11_3(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11):\n",
    "    return x3\n",
    "def rc_8_3(x1,x2,x3,x4,x5,x6,x7,x8):\n",
    "    return x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:40.142131Z",
     "start_time": "2019-10-15T17:37:40.056126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pc - parse context\n",
    "# arc - abstract rule context\n",
    "def arc_IT(rule):\n",
    "    def rc_IT(*args):\n",
    "        rez = rule(*args)\n",
    "        assert isinstance(rez,classes.StDeclinable)\n",
    "        if rez.chis=='mn': return None\n",
    "        if   rez.rod=='m': return 'он'\n",
    "        elif rez.rod=='g': return 'она'\n",
    "        elif rez.rod=='s': return 'оно'\n",
    "        else: raise TextError('wrong rod')\n",
    "    return rc_IT\n",
    "\n",
    "pc_IT_1 = alt(\n",
    "            seq([W('how'), W('many'), p_noun, px_HAVE_HAS, p_noun_ip, W('?'), \n",
    "                   p_noun_ip, px_HAVE_HAS,  p_noun, W('.')\n",
    "            ],arc_IT(rc_10_5)),\n",
    "            seq([p_noun_ip, alt(px_HAVE_HAS,p_TOBE), p_noun, W(';'), \n",
    "                   p_noun_ip, p_TOBE,  alt(p_noun,p_where), W('.')\n",
    "            ],arc_IT(rc_8_3)),\n",
    "            seq([W('where'), p_TOBE, p_noun_ip, W('?'), \n",
    "                   p_noun_ip, p_TOBE,  p_where, W('.')\n",
    "            ],arc_IT(rc_8_3)),\n",
    "            seq([p_noun_ip,W(','),W('where'), p_TOBE, p_noun_ip, W('?'), \n",
    "                   p_noun_ip, p_TOBE,  p_where, W('.')\n",
    "            ],arc_IT(rc_10_5)),\n",
    "            seq([W('where'), p_TOBE, p_noun_ip, W('?'), \n",
    "                   p_noun_ip, p_TOBE,  p_where, W('too'), W('.')\n",
    "            ],arc_IT(rc_9_3)),\n",
    "            seq([W('what'),W('colour'),p_TOBE,p_noun_ip, W('?'), \n",
    "                   p_noun_ip, p_TOBE,  p_noun, W('.')\n",
    "            ],arc_IT(rc_9_4))\n",
    ")\n",
    "pc_IT_2 = alt(\n",
    "            seq([px_HAVE_HAS, p_noun_ip, p_noun, W(','), p_noun_ip, W('?'), \n",
    "                 p_sentence,\n",
    "                 W('where'), p_TOBE, p_noun_ip, W('?')\n",
    "            ],arc_IT(rc_11_3)),\n",
    "            seq([px_HAVE_HAS, p_noun_ip, p_noun, W('?'), \n",
    "                 p_sentence,\n",
    "                 W('where'), p_TOBE, p_noun_ip, W('?')\n",
    "            ],arc_IT(rc_9_3)),\n",
    "        )\n",
    "\n",
    "dict_pronoun_ip['it'] = RuleContext('оно',dict_pronoun_ip['it'].vars,selectors = [\n",
    "    (-1,1,pc_IT_1),(-2,1,pc_IT_2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Запуск и отладка\n",
    "\n",
    "* `en2ru(s)` - переводит строку, возвращает строку\n",
    "* `d_en2ru(s)` - переводит строку, возвращает строку, дополнительно печатает процесс разбора\n",
    "* `pr_l_repr(s)` - печатает строку в тройных кавычках\n",
    "* `with_variants(variants,fun,s)` - устанавливает варианты, и потом вызывает fun(s).\n",
    "`variants` - список пар (RuleVars,n)\n",
    "* `decline(s,pads=['ip','rp','dp','vp','tp','pp'])` - переводит строку и выводит ее в разных падежах. Строка должна быть существительным\n",
    "* `parse_pat(patt,s)` == `patt(tokenize(s),0)`\n",
    "* `d_parse_pat(patt,s)` - дополнительно печатает процесс разбора\n",
    "* `scheme(s,detailed=1,nohtml = False)` - печатает схему разбора\n",
    "    \n",
    "    есть дополнительный аргумент datailed\n",
    "        0 - не печатает сквозные паттерны (которые без правил)\n",
    "        1 - дефолтный вывод\n",
    "        2 - дополнительно печатает нестрингифицированные объекты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:40.275139Z",
     "start_time": "2019-10-15T17:37:40.144131Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _en2ru(s): # main\n",
    "    ''' (text|.)* + warning-и\n",
    "    '''\n",
    "    s=tokenize(s)\n",
    "    if len(s)==0:\n",
    "        warning('no tokens')\n",
    "        return ''\n",
    "    \n",
    "    ret_s = ''\n",
    "    p=0\n",
    "    while p<len(s):\n",
    "        #print('ITERATION',p)\n",
    "        rezs= p_text(s,p)\n",
    "        if len(rezs)==0:\n",
    "            warning(\"CAN'T TRANSLATE: \"+s[p])\n",
    "            ret_s += (' | ' if p>0 else '')+ s[p]\n",
    "            p+=1\n",
    "        else:\n",
    "            assert len(rezs)==1\n",
    "            p1,r1 = rezs[0]\n",
    "            #print(p,p1,r1)\n",
    "            s1 = r1.tostr()\n",
    "            #print(p,p1,r1)\n",
    "            ret_s += (' | ' if p>0 else '')+ s1\n",
    "            if p>0:\n",
    "                warning('TRANSLATION BREAKS')\n",
    "            assert p1>p, rezs\n",
    "            p=p1\n",
    "    return ret_s\n",
    "\n",
    "def en2ru(s):\n",
    "    '''переводит строку, возвращает строку'''\n",
    "    parse_system.DEBUGGING=False\n",
    "    return _en2ru(s)\n",
    "\n",
    "def d_en2ru(s):\n",
    "    '''переводит строку, возвращает строку\n",
    "    \n",
    "    дополнительно пишет отладочный вывод разбора'''\n",
    "    l_d = parse_system.DEBUGGING\n",
    "    parse_system.DEBUGGING=True\n",
    "    try:\n",
    "        r=_en2ru(s)\n",
    "    finally:\n",
    "        parse_system.DEBUGGING=l_d\n",
    "    return r\n",
    "\n",
    "def c_en2ru(s):\n",
    "    '''переводит строку, возвращает строку\n",
    "    \n",
    "    дополнительно пишет отладочный вывод поиска контекстов'''\n",
    "    global CONTEXT_DEBUGGING\n",
    "    l_d = CONTEXT_DEBUGGING\n",
    "    CONTEXT_DEBUGGING=True\n",
    "    try:\n",
    "        r=_en2ru(s)\n",
    "    finally:\n",
    "        CONTEXT_DEBUGGING=l_d\n",
    "    return r\n",
    "\n",
    "def pr_l_repr(s):\n",
    "    \"\"\"печатает строку в тройных кавычках\"\"\"\n",
    "    print(\"'''\"+s+\"'''\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:40.394146Z",
     "start_time": "2019-10-15T17:37:40.277139Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def with_variants(variants,fun,s):\n",
    "    '''variants - список пар (RuleVars,n)'''\n",
    "    saves = {}\n",
    "    for k,v in variants:\n",
    "        saves[id(k)]=k.default\n",
    "        k.select(v)\n",
    "    try:\n",
    "        s = fun(s)\n",
    "    finally:\n",
    "        for k,v in variants:\n",
    "            k.select(saves[id(k)])\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:40.587157Z",
     "start_time": "2019-10-15T17:37:40.396146Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def decline(s,pads=['ip','rp','dp','vp','tp','pp']):\n",
    "    s=tokenize(s)\n",
    "    # добавить дочитывание точки и остаточных пробелов\n",
    "    rezs=[res for pos,res in p_noun(s,0) if pos==len(s)]\n",
    "    if len(rezs)!=1:\n",
    "        raise TextError(rezs)\n",
    "    tmp=rezs[0]\n",
    "    \n",
    "    m=[]\n",
    "    for p in pads:\n",
    "        #print(str(tmp))\n",
    "        prompt= \\\n",
    "            '' if p=='ip' else\\\n",
    "            'нет ' if p=='rp' else\\\n",
    "            'дать ' if p=='dp' else\\\n",
    "            'вижу ' if p=='vp' else\\\n",
    "            'творю ' if p=='tp' else\\\n",
    "            'думаю о ' if p=='pp' else\\\n",
    "            throw(ValueError('bad pad: '+p))\n",
    "        #rez=deepcopy(tmp)\n",
    "        tmp.pad=p\n",
    "        m.append(prompt+tmp.tostr())#        print(prompt+str(tmp))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:41.178190Z",
     "start_time": "2019-10-15T17:37:40.589157Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _parse_pat(patt,s):\n",
    "    s=tokenize(s)\n",
    "    return patt(s,0)\n",
    "\n",
    "def parse_pat(patt,s):\n",
    "    '''парсит строку паттерном, и возвращает не стрингифицированный объект'''\n",
    "    parse_system.DEBUGGING=False\n",
    "    return _parse_pat(patt,s)\n",
    "\n",
    "def d_parse_pat(patt,s):\n",
    "    '''парсит строку паттерном, и возвращает не стрингифицированный объект\n",
    "    \n",
    "    дополнительно пишет отладочный вывод'''\n",
    "    l_d = parse_system.DEBUGGING\n",
    "    parse_system.DEBUGGING=True\n",
    "    try:\n",
    "        r=_parse_pat(patt,s)\n",
    "    finally:\n",
    "        parse_system.DEBUGGING=l_d\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:41.299197Z",
     "start_time": "2019-10-15T17:37:41.180191Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def sch_print_rez0(rez,depth,s,detailed):\n",
    "    '''выводит исходное дерево слева направо'''\n",
    "    info = rez.parse_info\n",
    "    if hasattr(info,'p_start'):\n",
    "        print('  '*depth+' '+SAttrs().join( s[info.p_start : info.p_end] ))\n",
    "    if hasattr(info,'patterns') or hasattr(info,'rule_group'):\n",
    "        if hasattr(info,'patterns'):\n",
    "            #'<'+str(id(info.patterns))+'>'+\n",
    "            patterns = ' '.join(info.patterns2str()) if detailed>=1 else info.patterns2str()[0]\n",
    "        else:\n",
    "            patterns = ''\n",
    "        if hasattr(info,'rule_group'):\n",
    "            if type(info.rule_group)==list:\n",
    "                n = info.rule_group[0] if info.rule_group[0]!=0 else 1\n",
    "                rule = info.rule_group[n]\n",
    "                rules = str(n)+'/'+str(len(info.rule_group)-1)+' '\n",
    "            else:\n",
    "                rule = info.rule_group\n",
    "                rules = ''\n",
    "            rules += (rule.__name__ if callable(rule) else str(rule))\n",
    "        else:\n",
    "            rules = ''\n",
    "        print('  '*depth +' '+ patterns+' -> '+rules)\n",
    "    print('  '*depth+'*'+str(rez))\n",
    "    print('  '*depth+'*'+repr(rez))\n",
    "\n",
    "    if hasattr(rez,'talk'):\n",
    "        for x in rez.talk:\n",
    "            sch_print_rez0(x[1],depth+1,s,detailed)\n",
    "\n",
    "# создание узлов (+ преобразование rule_group)\n",
    "# ! - было исключение\n",
    "# ? - есть отключенные исключения\n",
    "class Node:\n",
    "    __slots__ = ['childs','p_start','p_end','patterns','rule','rez','str','html']\n",
    "    def make_html(self,cols,DISTANCE):\n",
    "        l = '_'*(cols[self.p_end]-cols[self.p_start]-DISTANCE)\n",
    "        \n",
    "        patts=[]\n",
    "        elseflag = False\n",
    "        disabled_exc = False\n",
    "        for p in self.rez.parse_info.patterns:\n",
    "            if p=='__ELSE__':\n",
    "                elseflag = True\n",
    "            elif type(p)==RuleVars:\n",
    "                disabled_exc = True\n",
    "            else:\n",
    "                s = ''\n",
    "                if disabled_exc:\n",
    "                    disabled_exc = False\n",
    "                    s+='?'\n",
    "                if elseflag:\n",
    "                    elseflag = False\n",
    "                    s+='!'\n",
    "                if len(s)!=0: s+=' '\n",
    "                ps = p.__name__ if callable(p) else p['__name__']\n",
    "                if len(patts)==0:\n",
    "                    s+='<a href=\"#'+ps+'\">'+ps+'</a>'\n",
    "                else:\n",
    "                    s+='(<a href=\"#'+ps+'\">'+ps+'</a>)'\n",
    "                patts.append(s)\n",
    "        \n",
    "        p0 = patts[0]\n",
    "        r = self.rule\n",
    "        s = self.str\n",
    "        pp = '<br>'.join(patts[1:])\n",
    "        \n",
    "        self.html = l+'<br>'+p0+'<br>'+r+'<br>'+s+'<br>'+pp\n",
    "        \n",
    "def sch_make_tree(struct):\n",
    "    '''возвращает пару (глубина, [Node-ы])'''\n",
    "    if hasattr(struct,'talk'):\n",
    "        if hasattr(struct.parse_info,'p_start'):\n",
    "            info = struct.parse_info\n",
    "            node = Node()\n",
    "            node.p_start = info.p_start\n",
    "            node.p_end = info.p_end\n",
    "            node.patterns = info.patterns2str()\n",
    "            if hasattr(info,'rule_group'):\n",
    "                if isinstance(info.rule_group,RuleVars):\n",
    "                    assert info.rule_group.default!=None, info.rule_group\n",
    "                    rule = info.rule_group.get_default()\n",
    "                    rules= ('c-' if type(info.rule_group)==RuleContext else '')+\\\n",
    "                        str(info.rule_group.default)+'/'+str(len(info.rule_group.vars))+' '\n",
    "                else:\n",
    "                    rule = info.rule_group\n",
    "                    rules = ''\n",
    "                node.rule = rules + (rule.__name__ if callable(rule) else str(rule))\n",
    "            else:\n",
    "                node.rule = ''\n",
    "            node.rez = struct\n",
    "            node.childs = []\n",
    "            depth = 0\n",
    "            for tup in struct.talk:\n",
    "                d,m = sch_make_tree(tup[1])\n",
    "                if d>depth: depth = d\n",
    "                node.childs+=m\n",
    "            node.childs.sort(key=lambda node:node.p_start)\n",
    "            return (depth+1,[node])\n",
    "        else:\n",
    "            mm = []\n",
    "            depth = 0\n",
    "            for tup in struct.talk:\n",
    "                d,m = sch_make_tree(tup[1])\n",
    "                if d>depth: depth = d\n",
    "                mm+=m\n",
    "            return (depth,mm)\n",
    "    elif hasattr(struct.parse_info,'p_start'):\n",
    "        # получется, всё, что не является структурой - обязано содержать parse_info ?\n",
    "        info = struct.parse_info\n",
    "        node = Node()\n",
    "        node.p_start = info.p_start\n",
    "        node.p_end = info.p_end\n",
    "        node.patterns = info.patterns2str()\n",
    "        if hasattr(info,'rule_group'):\n",
    "            if isinstance(info.rule_group,RuleVars):\n",
    "                rule = info.rule_group.get_default()\n",
    "                rules= ('c-' if type(info.rule_group)==RuleContext else '')+\\\n",
    "                    str(info.rule_group.default)+'/'+str(len(info.rule_group.vars))+' '\n",
    "            else:\n",
    "                rule = info.rule_group\n",
    "                rules = ''\n",
    "            node.rule = rules + (rule.__name__ if callable(rule) else str(rule))\n",
    "        else:\n",
    "            node.rule = ''\n",
    "        node.rez = struct\n",
    "        node.childs = []\n",
    "        return (1,[node])\n",
    "    else:\n",
    "        return (0,[])\n",
    "\n",
    "def sch_print_rez1(info,depth,s):\n",
    "    '''выводит преобразованное дерево слева направо'''\n",
    "    if hasattr(info,'p_start'):\n",
    "        print('  '*depth+' '+SAttrs().join( s[info.p_start : info.p_end] ))\n",
    "    patterns = ' '.join(info.patterns) if full else info.patterns[0]\n",
    "    print('  '*depth +' '+ patterns+' -> '+info.rule)\n",
    "    print('  '*depth+'*'+str(info.rez))\n",
    "\n",
    "    if hasattr(info,'childs'):\n",
    "        for x in info.childs:\n",
    "            sch_print_rez1(x,depth+1,s)\n",
    "\n",
    "def sch_make_lines(node,lines,cols,DISTANCE):\n",
    "    '''преобразует дерево в таблицу'''\n",
    "    dd=0 # уровень, номер Лайна. У детей меньше чем у родителей.\n",
    "    for c in node.childs:\n",
    "        d = sch_make_lines(c,lines,cols,DISTANCE)\n",
    "        if d>dd: dd = d\n",
    "\n",
    "    # приводим результат к текстовой форме\n",
    "    node.str = repr(node.rez.tostr())[1:-1]\n",
    "    # приводим паттерны в надлежащий вид\n",
    "    for i in range(1,len(node.patterns)):\n",
    "        node.patterns[i] = '('+node.patterns[i]+')'\n",
    "\n",
    "    # вычисляем кол-во строк в Лайне\n",
    "    if len(node.patterns)>lines[dd].h: lines[dd].h = len(node.patterns)\n",
    "\n",
    "    # длина строки в символах\n",
    "    maxlen = max(len(node.rule),len(node.str),max([len(i) for i in node.patterns]))\n",
    "    dlen = (maxlen+DISTANCE) - (cols[node.p_end]-cols[node.p_start])\n",
    "    #print(node.str,maxlen,dlen)\n",
    "    # модифицируем позиции столбцов\n",
    "    if dlen>0:\n",
    "        for i in range(node.p_end,len(cols)):\n",
    "            cols[i]+=dlen\n",
    "\n",
    "    # присваиваем объект в таблицу\n",
    "    lines[dd].line[node.p_start] = node\n",
    "    return dd+1\n",
    "\n",
    "def sch_print_table(s,cols,lines,DISTANCE,detailed):\n",
    "    def inde(s,p_start,p_end):\n",
    "        '''дополняет строку пробелами, чтобы заполнить нужные ячейки'''\n",
    "        return s+' '*(cols[p_end]-cols[p_start]-len(s))\n",
    "\n",
    "    # выводим исходную строку\n",
    "    for i in range(len(s)):\n",
    "        print(inde(s[i],i,i+1),end='')\n",
    "    print()\n",
    "\n",
    "    for line_ in lines:\n",
    "        line=line_.line\n",
    "\n",
    "        # _______\n",
    "        i=0\n",
    "        l=''\n",
    "        while i<len(s):\n",
    "            if line[i]==None:\n",
    "                l+=inde('',i,i+1)\n",
    "                i+=1\n",
    "            else:\n",
    "                l+='_'*(cols[line[i].p_end]-cols[line[i].p_start]-DISTANCE)+' '*DISTANCE\n",
    "                i=line[i].p_end\n",
    "        print(l)\n",
    "\n",
    "        # patterns[0]\n",
    "        i=0\n",
    "        l=''\n",
    "        while i<len(s):\n",
    "            if line[i]==None:\n",
    "                l+=inde('',i,i+1)\n",
    "                i+=1\n",
    "            else:\n",
    "                l+=inde(line[i].patterns[0],line[i].p_start,line[i].p_end)\n",
    "                i=line[i].p_end\n",
    "        print(l)\n",
    "\n",
    "        # rule\n",
    "        i=0\n",
    "        l=''\n",
    "        while i<len(s):\n",
    "            if line[i]==None:\n",
    "                l+=inde('',i,i+1)\n",
    "                i+=1\n",
    "            else:\n",
    "                l+=inde(line[i].rule,line[i].p_start,line[i].p_end)\n",
    "                i=line[i].p_end\n",
    "        print(l)\n",
    "\n",
    "        # rez\n",
    "        i=0\n",
    "        l=''\n",
    "        while i<len(s):\n",
    "            if line[i]==None:\n",
    "                l+=inde('',i,i+1)\n",
    "                i+=1\n",
    "            else:\n",
    "                l+=inde(line[i].str,line[i].p_start,line[i].p_end)\n",
    "                i=line[i].p_end\n",
    "        print(l)\n",
    "\n",
    "        # patterns[j]\n",
    "        if detailed>=1:\n",
    "            for j in range(1,line_.h):\n",
    "                i=0\n",
    "                l=''\n",
    "                while i<len(s):\n",
    "                    if line[i]==None or j>=len(line[i].patterns):\n",
    "                        l+=inde('',i,i+1)\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        l+=inde(line[i].patterns[j],line[i].p_start,line[i].p_end)\n",
    "                        i=line[i].p_end\n",
    "                print(l)\n",
    "\n",
    "def scheme_pat(patt,s,detailed=1,nohtml = False):\n",
    "    '''печатает схему разбора\n",
    "    \n",
    "    есть дополнительный аргумент datailed\n",
    "        0 - не печатает сквозные паттерны (которые без правил)\n",
    "        1 - дефолтный вывод\n",
    "        2 - дополнительно печатает нестрингифицированные объекты\n",
    "    '''\n",
    "    # токенизируем строку\n",
    "    s=tokenize(s)\n",
    "    \n",
    "    # парсим строку\n",
    "    ParseInfo.enabled = True\n",
    "    try:\n",
    "        rezs=debug_pp(patt)(s,0)\n",
    "    finally:\n",
    "        ParseInfo.enabled = False\n",
    "        \n",
    "    return scheme_print(s,rezs,detailed,nohtml)\n",
    "        \n",
    "def scheme(s,detailed=1,nohtml = False):\n",
    "    '''печатает схему разбора\n",
    "    \n",
    "    есть дополнительный аргумент datailed\n",
    "        0 - не печатает сквозные паттерны (которые без правил)\n",
    "        1 - дефолтный вывод\n",
    "        2 - дополнительно печатает нестрингифицированные объекты\n",
    "    '''\n",
    "    # токенизируем строку\n",
    "    s=tokenize(s)\n",
    "    \n",
    "    # парсим строку\n",
    "    ParseInfo.enabled = True\n",
    "    try:\n",
    "        rezs=maxlen_filter(alt(p_sentence,p_phrase,p_question_phrase)(s,0))\n",
    "    finally:\n",
    "        ParseInfo.enabled = False\n",
    "        \n",
    "    return scheme_print(s,rezs,detailed,nohtml)\n",
    "        \n",
    "def scheme_print(s,rezs,detailed=1,nohtml = False):\n",
    "    '''печатает схему разбора\n",
    "    \n",
    "    есть дополнительный аргумент datailed\n",
    "        0 - не печатает сквозные паттерны (которые без правил)\n",
    "        1 - дефолтный вывод\n",
    "        2 - дополнительно печатает нестрингифицированные объекты\n",
    "    '''\n",
    "    hstr = '' # html_str\n",
    "    def h_print(s=''):\n",
    "        nonlocal nohtml\n",
    "        if nohtml:\n",
    "            print(s)\n",
    "        else:\n",
    "            nonlocal hstr\n",
    "            hstr+=s+'\\n'\n",
    "        \n",
    "    h_print(str(len(rezs))+' результатов')\n",
    "    # анализируем каждый результат\n",
    "    for end,rez in rezs:\n",
    "        h_print()\n",
    "        # простой построчный вывод узлов результата\n",
    "        if detailed==2:\n",
    "            rez.pull_deferred()\n",
    "            sch_print_rez0(rez,0,s,detailed)\n",
    "        \n",
    "        # простой вывод узлов\n",
    "        if 0:\n",
    "            rez.pull_deferred()\n",
    "            \n",
    "        # создание дерева\n",
    "        depth,mm = sch_make_tree(rez)\n",
    "        assert len(mm)==1, mm\n",
    "        tree=mm[0]\n",
    "        \n",
    "        # простой вывод узлов\n",
    "        if 0:\n",
    "            print('depth=',depth)\n",
    "            sch_print_rez1(tree,0,s)\n",
    "        \n",
    "        DISTANCE = 2\n",
    "        cols = [] # позиции столбцов - кол-во символов от начала строки до начала столбца\n",
    "        pos=0\n",
    "        for word in s:\n",
    "            cols.append(pos)\n",
    "            pos+=len(word)+DISTANCE\n",
    "        cols.append(pos)\n",
    "        \n",
    "        class Line:\n",
    "            __slots__=['h','line']\n",
    "            def __init__(self,h,l):\n",
    "                self.h = h      # количество строчек в чинии\n",
    "                self.line = l   # список объектов (Node-ов) по столбцам\n",
    "                \n",
    "        lines = [Line(0,[None for i in range(len(s))]) for j in range(depth)]\n",
    "        dd = sch_make_lines(tree,lines,cols,DISTANCE)\n",
    "        assert dd==depth\n",
    "        \n",
    "        if nohtml:\n",
    "            sch_print_table(s,cols,lines,DISTANCE,detailed)\n",
    "        \n",
    "        else:\n",
    "            def make_html(n):\n",
    "                n.make_html(cols,DISTANCE)\n",
    "                for i in n.childs:\n",
    "                    make_html(i)\n",
    "            make_html(tree)\n",
    "\n",
    "            ss = '<tr>'+''.join(['<td>'+si+'</td>' for si in s])+'</tr>\\n'\n",
    "            for ll in lines:\n",
    "                sl = '<tr>\\n'\n",
    "                p_end=0\n",
    "                for l in ll.line:\n",
    "                    if l!=None:\n",
    "                        sl+='<td></td>'*(l.p_start-p_end)\n",
    "                        sl+='<td colspan=\"'+str(l.p_end-l.p_start)+'\">'+l.html+'</td>\\n'\n",
    "                        p_end = l.p_end\n",
    "                ss+=sl+'</tr>\\n\\n'\n",
    "\n",
    "            h_print('<table>'+ss+'\\n</table>\\n')\n",
    "\n",
    "    if not nohtml:\n",
    "        return HTML(hstr)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:41.389203Z",
     "start_time": "2019-10-15T17:37:41.301198Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cache_stat():\n",
    "    stat = {}\n",
    "    for (pos,fun),v in parse_system.global_cache.items():\n",
    "        if pos in stat:\n",
    "            stat[pos]+=1\n",
    "        else:\n",
    "            stat[pos]=1\n",
    "    {k:(\n",
    "        [(d[0],str(d[1])) for d in v] \\\n",
    "        #len(v)\\\n",
    "        if type(v)==list \n",
    "        else v\n",
    "    ) for k,v in parse_system.global_cache.items() }\n",
    "    if len(stat)>0:\n",
    "        print(sum(stat)/len(stat))\n",
    "    return stat\n",
    "cache_stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:41.487208Z",
     "start_time": "2019-10-15T17:37:41.391203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я вижу джем и одну чашку.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('I see jam and one cup.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:41.575213Z",
     "start_time": "2019-10-15T17:37:41.495209Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def en2ru(s):\n",
      "    '''переводит строку, возвращает строку'''\n",
      "    parse_system.DEBUGGING=False\n",
      "    return _en2ru(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "lines = inspect.getsource(en2ru)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.153361Z",
     "start_time": "2019-10-15T17:37:41.583214Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Lesson 1 ---\n",
      "--- Lesson 2 ---\n",
      "--- Lesson 3 ---\n",
      "--- Lesson 4 (? увидь кота ?) ---\n",
      "--- Lessons 5, 6 ---\n",
      "--- Lesson 7 ---\n",
      "--- Lesson 8 (открывающие кавычки...) ---\n",
      "--- Lesson 8.1 ---\n",
      "--- Lesson 9 ---\n",
      "--- Lesson 10 ---\n",
      "--- Lesson 11 ---\n",
      "--- Lesson 12 ---\n",
      "--- Lesson 13 ---\n",
      "--- Lesson 14 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tests\n",
    "tests = reload(tests)\n",
    "tests.init(parse_system,en_dictionary,\n",
    "           en2ru,with_variants,decline,scheme,d_en2ru,pr_l_repr,\n",
    "           p_noun,p_noun1,r_noun_comma_noun,rv_noun_HAVE_noun,\n",
    "          1,False)\n",
    "tests.test1()\n",
    "tests.test2()\n",
    "tests.test3()\n",
    "tests.test4()\n",
    "tests.test5and6()\n",
    "tests.test7()\n",
    "tests.test8()\n",
    "tests.test8_1()\n",
    "tests.test9()\n",
    "tests.test10()\n",
    "tests.test11()\n",
    "tests.test12()\n",
    "tests.test13()\n",
    "tests.test14()\n",
    "tests.finalize()\n",
    "tests.TEST_ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.170362Z",
     "start_time": "2019-10-15T17:37:44.155361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'что это?'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('what is this?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.331371Z",
     "start_time": "2019-10-15T17:37:44.178362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CAN'T TRANSLATE: look\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: flower\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: these\n",
      "CAN'T TRANSLATE: flowers\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: those\n",
      "CAN'T TRANSLATE: flowers\n",
      "TRANSLATION BREAKS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'look | , | что это? | оно -- некоторое | flower | . | these | flowers | стань красный | и | those | flowers | \\nстань синий.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('''Look, what is this? It is a flower.\n",
    "These flowers are red and those flowers\n",
    "are blue.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.467379Z",
     "start_time": "2019-10-15T17:37:44.333371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''Что это? | оно --\n",
      "некоторое | rose | . | \n",
      "Что это? | оно --\n",
      "некоторое | violet | . | стань этот\tнекоторый | violet | or | \n",
      "некоторый | rose | ? | оно --\tнекоторое | rose | . | стань этот\tнекоторый | rose | тоже | ? | \n",
      "Нет, это не так.'''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: rose\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: violet\n",
      "TRANSLATION BREAKS\n",
      "multiple results:\n",
      "стань этот\tнекоторый\n",
      "этот\tнекоторый\n",
      "этот --\tнекоторый\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: violet\n",
      "CAN'T TRANSLATE: or\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: rose\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: rose\n",
      "TRANSLATION BREAKS\n",
      "multiple results:\n",
      "стань этот\tнекоторый\n",
      "этот\tнекоторый\n",
      "этот --\tнекоторый\n",
      "TRANSLATION BREAKS\n",
      "CAN'T TRANSLATE: rose\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n",
      "TRANSLATION BREAKS\n"
     ]
    }
   ],
   "source": [
    "pr_l_repr(en2ru('''What is this? It is\n",
    "a rose.\n",
    "What is this? It is\n",
    "a violet.\n",
    "Is this\ta\tviolet\tor\n",
    "a\trose? It\tis\ta rose.\n",
    "Is this\ta rose too?\n",
    "No, it is not.'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.760395Z",
     "start_time": "2019-10-15T17:37:44.475379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CAN'T TRANSLATE: violets\n",
      "не совпадают числа числ. и сущ.:\n",
      "многокрасный\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "(<class 'classes.StNum'>, 'maindep', <class 'classes.StAdj'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-0c0e09161e93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmany\u001b[0m \u001b[0mred\u001b[0m \u001b[0mroses\u001b[0m \u001b[0mtoo\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mShe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mmany\u001b[0m \u001b[0mflowers\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m garden.'''))\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-f8b698878e2b>\u001b[0m in \u001b[0;36men2ru\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;34m'''переводит строку, возвращает строку'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mparse_system\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUGGING\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_en2ru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0md_en2ru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-f8b698878e2b>\u001b[0m in \u001b[0;36m_en2ru\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#print('ITERATION',p)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mp_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CAN'T TRANSLATE: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-4a85a5e1a536>\u001b[0m in \u001b[0;36mp_text\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0msentence_points\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# отбрасываем остальные результаты\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-776f12393ff3>\u001b[0m in \u001b[0;36mp_sentence\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m     18\u001b[0m         rezs=p_alt(s,p,\n\u001b[0;32m     19\u001b[0m             \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_phrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_question_phrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         )\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m# не работает, т.к. всё закешировалось\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpatt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_seq_context_info\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \t\t\treturn none_filter([  (pos,rule_group_adder(context_adder(rule,rez,p))) \\\n\u001b[1;32m--> 711\u001b[1;33m \t\t\t\t\t\t\t\t\tfor pos,rez in sp_seq(s,p,patterns)])\n\u001b[0m\u001b[0;32m    712\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \t\t\treturn none_filter([  (pos,                 context_adder(rule,rez,p) ) \\\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36msp_seq\u001b[1;34m(str, pos, patterns)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# в дальнейшем отключить повторное вычисление\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# продолжения для одинаковых позиций\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-8a7d6640756d>\u001b[0m in \u001b[0;36mp_phrase\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_verb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_NET_COMMA_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_noun\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_verb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_noun_COMMA_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'thank'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'you'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_SPASIBO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mELSE\u001b[0m   \u001b[1;31m#    assert ELSE больше не встречается\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0mr_rezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mr_rezs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_rezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-73c3e120bf25>\u001b[0m in \u001b[0;36mp_verb\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mp_verb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'and'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_verb1\u001b[0m \u001b[1;33m]\u001b[0m        \u001b[1;33m,\u001b[0m\u001b[0mr_verb_I_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#ELSE, # переход к следующему уровню\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mp_verb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mELSE\u001b[0m   \u001b[1;31m#    assert ELSE больше не встречается\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0mr_rezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mr_rezs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_rezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_seq_context_info\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \t\t\treturn none_filter([  (pos,rule_group_adder(context_adder(rule,rez,p))) \\\n\u001b[1;32m--> 711\u001b[1;33m \t\t\t\t\t\t\t\t\tfor pos,rez in sp_seq(s,p,patterns)])\n\u001b[0m\u001b[0;32m    712\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \t\t\treturn none_filter([  (pos,                 context_adder(rule,rez,p) ) \\\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36msp_seq\u001b[1;34m(str, pos, patterns)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# в дальнейшем отключить повторное вычисление\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# продолжения для одинаковых позиций\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-025ea35a24d7>\u001b[0m in \u001b[0;36mp_verb1\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mp_noun_verb1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'to'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_verb3\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_to_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;31m#ELSE, # переход к следующему уровню\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mp_verb3\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrv_rule_povel_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m def r_to_verb(_t,_v): return StVerb([\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpatt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-b88f84fcc363>\u001b[0m in \u001b[0;36mp_noun_verb1\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_noun_ip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_TOBE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'not'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_noun\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_noun_X_NE_noun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mp_noun_ip\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mp_verb3\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_noun_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mp_noun_ip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_verb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'too'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_noun_TOZHE_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#ELSE, # переход к следующему уровню\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mELSE\u001b[0m   \u001b[1;31m#    assert ELSE больше не встречается\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0mr_rezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[0mr_rezs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_rezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_seq_context_info\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \t\t\treturn none_filter([  (pos,rule_group_adder(context_adder(rule,rez,p))) \\\n\u001b[1;32m--> 711\u001b[1;33m \t\t\t\t\t\t\t\t\tfor pos,rez in sp_seq(s,p,patterns)])\n\u001b[0m\u001b[0;32m    712\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \t\t\treturn none_filter([  (pos,                 context_adder(rule,rez,p) ) \\\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36msp_seq\u001b[1;34m(str, pos, patterns)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m                 \u001b[0mtmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msp_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mrr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m                         \u001b[0mrr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36msp_seq\u001b[1;34m(str, pos, patterns)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msp_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# в дальнейшем отключить повторное вычисление\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-cc977ee910bc>\u001b[0m in \u001b[0;36mp_verb3\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m      3\u001b[0m def p_verb3(s,p): return p_alt(s,p,\n\u001b[0;32m      4\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'can'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_verb3_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_CAN_verb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mp_verb3_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m def r_CAN_verb(c,v): return StVerb([\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpatt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-3d06b7261ef3>\u001b[0m in \u001b[0;36mp_verb3_1\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mp_verb3_komu_chto\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mp_HAVE_noun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mp_TOBE_noun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpatt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-1cd90f3c5228>\u001b[0m in \u001b[0;36mp_HAVE_noun\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpx_HAVE_HAS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_noun\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_NE_IMET_noun_vp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpx_HAVE_HAS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_IMET\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpx_HAVE_HAS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'not'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_NE_IMET\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m      9\u001b[0m def r_NE_IMET_noun_vp(_v,no,_n): return StVerb([\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpatt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_seq_context_info\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \t\t\treturn none_filter([  (pos,rule_group_adder(context_adder(rule,rez,p))) \\\n\u001b[1;32m--> 711\u001b[1;33m \t\t\t\t\t\t\t\t\tfor pos,rez in sp_seq(s,p,patterns)])\n\u001b[0m\u001b[0;32m    712\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \t\t\treturn none_filter([  (pos,                 context_adder(rule,rez,p) ) \\\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36msp_seq\u001b[1;34m(str, pos, patterns)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m                 \u001b[0mtmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msp_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mrr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m                         \u001b[0mrr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36msp_seq\u001b[1;34m(str, pos, patterns)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msp_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# в дальнейшем отключить повторное вычисление\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-6ee443763cca>\u001b[0m in \u001b[0;36mp_noun\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m      6\u001b[0m                  \u001b[1;31m#ELSE, # переход к следующему уровню\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                  \u001b[1;31m# идет конфликт с and-ом из глаголов\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mp_noun1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     10\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdebug_pp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpatt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_seq_context_info\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \t\t\treturn none_filter([  (pos,rule_group_adder(context_adder(rule,rez,p))) \\\n\u001b[1;32m--> 711\u001b[1;33m \t\t\t\t\t\t\t\t\tfor pos,rez in sp_seq(s,p,patterns)])\n\u001b[0m\u001b[0;32m    712\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \t\t\treturn none_filter([  (pos,                 context_adder(rule,rez,p) ) \\\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36msp_seq\u001b[1;34m(str, pos, patterns)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# в дальнейшем отключить повторное вычисление\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# продолжения для одинаковых позиций\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# <<<<<================== CALL FUN ======================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlist\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'паттерн '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' вернул неправильный тип'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-952fae800a4e>\u001b[0m in \u001b[0;36mp_noun1\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mp_numeral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_noun2\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_numeral_noun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#ELSE, # переход к следующему уровню\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mp_noun2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_pronoun_dp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdebug_pp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_alt\u001b[1;34m(s, p, *args)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[0mrezs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mpatt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                         \u001b[0mrezs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrez_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrezs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mp_seq_context_info\u001b[1;34m(s, p)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \t\t\treturn none_filter([  (pos,rule_group_adder(context_adder(rule,rez,p))) \\\n\u001b[1;32m--> 711\u001b[1;33m \t\t\t\t\t\t\t\t\tfor pos,rez in sp_seq(s,p,patterns)])\n\u001b[0m\u001b[0;32m    712\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \t\t\treturn none_filter([  (pos,                 context_adder(rule,rez,p) ) \\\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \t\t\treturn none_filter([  (pos,rule_group_adder(context_adder(rule,rez,p))) \\\n\u001b[1;32m--> 711\u001b[1;33m \t\t\t\t\t\t\t\t\tfor pos,rez in sp_seq(s,p,patterns)])\n\u001b[0m\u001b[0;32m    712\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mParseInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mContextInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \t\t\treturn none_filter([  (pos,                 context_adder(rule,rez,p) ) \\\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\parse_system.py\u001b[0m in \u001b[0;36mcontext_adder\u001b[1;34m(rule, rezs, pos)\u001b[0m\n\u001b[0;32m    685\u001b[0m                                 \u001b[0mfirst_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrez\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrule_group\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrule_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mRuleContext\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m                 \u001b[0mrez\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrezs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrez\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mrez\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrule\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mnull_handler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-952fae800a4e>\u001b[0m in \u001b[0;36mr_numeral_noun\u001b[1;34m(num, n)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquantity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m            \u001b[0mchis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0modush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0modush\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaindep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     ],quantity=num.quantity)\n\u001b[0m",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\classes.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, word, quantity, o, r, c, p)\u001b[0m\n\u001b[0;32m    731\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mquantity\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2-4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'>=5'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'quantity must be \"1\", \"2-4\" or \">=5\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquantity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                 \u001b[0mStDeclinable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\classes.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, word, o, r, c, p)\u001b[0m\n\u001b[0;32m    551\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtalk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtalk_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                         \u001b[0mfound\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\wiki-RBMT\\classes.py\u001b[0m in \u001b[0;36mtalk_checker\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtalk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                         \u001b[1;32massert\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobediences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobediences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobediences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;31m#def _assert(x,y=None):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: (<class 'classes.StNum'>, 'maindep', <class 'classes.StAdj'>)"
     ]
    }
   ],
   "source": [
    "pr_l_repr(en2ru('''That girl has many violets in her garden. She has\n",
    "many red roses too. She\n",
    "has many flowers in her\n",
    "garden.'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.803398Z",
     "start_time": "2019-10-15T17:37:35.485Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_l_repr(en2ru('''Is this a chicken?\n",
    "No, it is not. What\n",
    "is this? It is a bird.\n",
    "Where is the bird?\n",
    "It is in the cage.\n",
    "Is this bird big or\n",
    "little? It is little.'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.803398Z",
     "start_time": "2019-10-15T17:37:35.485Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_l_repr(en2ru('''Is this a stick? No, it is\n",
    "not. What is this? It is\n",
    "an umbrella. What colour is\n",
    "the umbrella? It is black.\n",
    "How many umbrellas\n",
    "have you? I have two umbrellas.\n",
    "Give me one umbrella!'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.803398Z",
     "start_time": "2019-10-15T17:37:35.485Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_l_repr(en2ru('''This bird is in the cage.\n",
    "This girl is in the room.\n",
    "That rose is red.\n",
    "That flower is yellow.\n",
    "This book is on the table.\n",
    "This kitten is in the box.\n",
    "This spoon is in the cup.\n",
    "That violet is little.\n",
    "That rose is good.'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.803398Z",
     "start_time": "2019-10-15T17:37:35.485Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_l_repr(en2ru('''These birds are in the tree.\n",
    "These girls are in the garden.\n",
    "Those roses are red.\n",
    "Those flowers are not yellow.\n",
    "These books are on the table.\n",
    "These kittens are under the bed.\n",
    "These spoons are on the dish.\n",
    "Those violets are very big.\n",
    "Those roses are little.'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.803398Z",
     "start_time": "2019-10-15T17:37:35.485Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_l_repr(en2ru('''I have good trousers. What colour are\n",
    "they?\n",
    "They are grey. These trousers are not\n",
    "bad.'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.803398Z",
     "start_time": "2019-10-15T17:37:35.485Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_l_repr(en2ru('''What has that girl in\n",
    "her garden?\n",
    "Has she many flowers\n",
    "in her garden?\n",
    "Where is this book?\n",
    "Where are these birds?\n",
    "Where is that kitten?\n",
    "What colour are those\n",
    "roses?\n",
    "Are these trousers bad?\n",
    "Is that violet big?'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:59.153219Z",
     "start_time": "2019-10-15T17:37:54.446949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook en2ru.ipynb to script\n",
      "[NbConvertApp] Writing 76350 bytes to en2ru.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script en2ru.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## составляем основную грамматику"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "выбираем варианты вручную\n",
    "пока в одном тексте не начнут требоваться разные варианты одного правила\n",
    "\n",
    "на боевое применение не выходим\n",
    "пока не будут пройдены времена глаголов\n",
    "\n",
    "КОДИТЬ И ДЕБАЖИТЬ ТЕКУЩЕЕ\n",
    "13) где?\n",
    "14) какого цвета?\n",
    "15) посмотри\n",
    "16) что у тебя есть?\n",
    "17) что это за <животное>?\n",
    "18) Polly's quail\n",
    "19) как тебя зовут?\n",
    "20) \n",
    "21) сколько тебе лет?\n",
    "22) take, give...\n",
    "23) can\n",
    "24) may, must\n",
    "25) must\n",
    "26) there is\n",
    "27) is there?\n",
    "28)\n",
    "29) когда? тогда\n",
    "30) рифма\n",
    "31) сравнительны прилагательные\n",
    "32) другая рифма\n",
    "33) скороговорка\n",
    "34) \n",
    "35)\n",
    "36)\n",
    "37)\n",
    "38) мой, твой\n",
    "39)\n",
    "стандартные фразы\n",
    "3 рассказа\n",
    "\n",
    "автовыбор склонений/спряжений прилагательных и глаголов\n",
    "сделать устранение конфликтов исключений\n",
    "\n",
    "\n",
    "два рыжих кота\n",
    "вижу двух рыжих котов\n",
    "вижу два горячих утюга\n",
    "два пирожных\n",
    "\n",
    "add_skl_suffix\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.807398Z",
     "start_time": "2019-10-15T17:37:35.513Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decline('two watches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.808398Z",
     "start_time": "2019-10-15T17:37:35.520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pr_l_repr(en2ru('''\n",
    "Boy: Where is your doll?\n",
    "Girl: My doll is on the bed.\n",
    "Boy: Where is your ball?\n",
    "Girl: It is under the table.\n",
    "Boy: Have you red ribbons?\n",
    "Girl: Yes, I have.\n",
    "Boy: Where are your red ribbons:\n",
    "Girl: They are in the box.\n",
    "Boy: Show me your ribbons! Thank you.\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:37:44.810398Z",
     "start_time": "2019-10-15T17:37:35.528Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "en2ru('It \\nis black.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## придумываем способ выборов вариантов (контекстных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "\n",
    "git-ветка с исключениями\n",
    "    исключения на несколько предложений\n",
    "     - не правильно, контексты - не синтаксические конструкции\n",
    "git-ветка с нейросетью\n",
    "    научится...\n",
    "git-ветка с другим жестким алгоритмом\n",
    "    придумать...\n",
    "\n",
    "    работа с деревом вглубь:\n",
    "        просмотр вглубь возможен\n",
    "\n",
    "        у каждого узла ссылка на правило и его аргументы\n",
    "        в узлах дерева поля \n",
    "            context_dep\n",
    "                True - узел зависит от контекста\n",
    "                    ссылка на правило, также принимат контекст\n",
    "                False - узел не зависит от контекста\n",
    "            context_dep_srcs - массив номеров - \n",
    "                какие аргументы правила зависят от контекста (или их потомки зависят от контекста)\n",
    "                т.е. какие аргументы правила требую ремейка в случае изменения контекста\n",
    "\n",
    "            context(может отсутствовать) - словарь (строка, ссылка на узел), который является контекстом\n",
    "                - устанавливается в правилах\n",
    "        функция context_remake(node,context)\n",
    "\n",
    "статистика использования паттернов\n",
    "статистика повторяющихся структур в тестах (разделить тесты на несвязанные предложения)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## __ по ходу дела по мере необходимости улучшаем гуй, в jupyter notebook-е\n",
    "виджетами и прочим  \n",
    "а также добавляем возможность переводить html и tex\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## делаем web-GUI на javascript-е\n",
    "\n",
    "выбор паттернов и правил в зависимости от времени "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "watch, двое, трое, пятеро\n",
    "\n",
    "scheme('it')\n",
    "\n",
    "...\n",
    "для больших текстов p_sentence будет делать срез со своей позции до конца\n",
    "    - чтобы обновить кэши ф-ций\n",
    "\n",
    "исключения парсить, если регулярным образом распарсилось\n",
    "    каждая функция будет с аргументом: парсить или нет исключения\n",
    "\n",
    "атрибуты слов: (теги)\n",
    "отображение открывающейся кавычки (SAttrs.join)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
