{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Зачем всё это?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Есть машинный перевод и есть автоматизированный перевод. \n",
    "\n",
    "Машинный перевод дает 100% автоматизации и не позволяет вмешиваться в процесс перевода (только в результат). Конечно у многих машинных переводчиков есть функция \"предложить перевод\", но я не понимаю, как она работает, и работает ли хоть как-то вообще. Однажды я всё-таки заметил, как это работает: в яндекс-переводчике предложил перевод слова (уже не помню какого), и через сутки до него дошло, как надо переводить это слово. Через сутки, Карл!\n",
    "\n",
    "Автоматизированный перевод дает где-то 15-20% автоматизации. Помимо словарей, глоссариев и прочей справочной информации, самая продвинутая (известная мне) технология - это память переводов, когда человек вручную переводит предложения, а система запоминает эти переводы, и если встречается предложение, которое было переведено раньше (или _похожее_ на него), его перевод подставляется автоматически. Но какова вероятность встретить в тексте 2 одинаковых предложения, если в них больше трёх слов?\n",
    "\n",
    "Целью данного переводчика является автоматизация 90%. Не 100 и не 20. А также мгновенное вступление изменений в силу. Ну и возможность залезть в код."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Основной принцип"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "p_паттерн парсит текст (str, pos), \n",
    "    вызывая другие паттерны, возвращающие древовидные структуры\n",
    "    эти древовидные структуры передает одному из правил\n",
    "        (остальные вызовы правил закомментированы \n",
    "            - в рамках одного текста каждый паттерн имеет ровно 1 смысл)\n",
    "    и возвращает (pos, результат этого правила), помещенный в массив\n",
    "    \n",
    "    /*пока на ошибках парсинга концентрировать не будем*/\n",
    "    если ничего не удалось распарсить, ???возвращаемый массив будет пустым???\n",
    "    если удалось распарсить несколько вариантов - в массиве будет насколько вариантов\n",
    "        сначала парсятся все исключения\n",
    "        потом парсятся все обычные варианты (если нет исключений)\n",
    "```\n",
    "\n",
    "```\n",
    "r_правило получает список древовидных структур\n",
    "    обрабатывает их по определенному правилу\n",
    "    возвращает древовидную структуру\n",
    "```\n",
    "\n",
    "```\n",
    "древовидная структура - map, со следующими ключами\n",
    "    type: 'noun'/'adj'/'verb'/'num'/... - определяем через isinstance()\n",
    "    постоянные параметры (для сущ.: род, число)\n",
    "    переменные параметры (для сущ.: падеж)\n",
    "    talk: массив древовидных структур\n",
    "        или пар (тип, слово), где тип - main/punct/other\n",
    "```\n",
    "\n",
    "```\n",
    "str(древовидная структура)\n",
    "    превращает древовидную структуру в строку\n",
    "```\n",
    "\n",
    "```\n",
    "для каждого типа элемента древовидной структуры будет map\n",
    "    где каждой строке (для сущ. - слово в и.п.) будет соответствовать\n",
    "        структура данных, которая вместе в переменными параметрами передается в \n",
    "        sh_функция для этого типа элемента древовидной структуры\n",
    "            которая будет возвращать слово в соотв. форме (для сущ. в соотв. падеже)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Что с этим делать дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "В дальнейшем предполагается, что паттерны и правила будут писать пользователи\n",
    "грамматика не преобразовывается в LL(1) или какой-то другой промежуточный формат,\n",
    "а парсится как есть, с возвратами (LL(*)), по этому результаты нетерминалов кэшируются.\n",
    "Также стоит защита от зацикливания.\n",
    "Никто не обещал, что грамматика будет однозначной, \n",
    "поэтому каждый нетерминал возвращает массив результатов.\n",
    "Но в конечном итоге таких результатов должно быть немного.\n",
    "Ситуация, когда получаются одинаковые результаты явлется нежелательной.\n",
    "\n",
    "В дальнейшем предполагается, что будет центральная грамматика, \n",
    "а у ее правил пользователи будут создавать исключения.\n",
    "Паттерн A является исключением паттерна B, если \n",
    "всё что может разобрать паттерн A может разобрать паттерн B,\n",
    "т.е. A задает подъязык языка B, \n",
    "т.е. A является частным случаем B (но связано с другим правилом).\n",
    "Сначала парсится B, и если это оказалось удачным, парсится A.\n",
    "Если А распарсилось неудачно, то результатом станосится результат B,\n",
    "а если удачно - то результат B отбрасывается и результатом станосится результат A.\n",
    "\n",
    "В дальнейшем предполагается возможность каждый паттерн связывать с \n",
    "набором правил, а точнее с одним правилом из заданного набора.\n",
    "А также возможность эти наборы пополнять.\n",
    "Одним из правил перевода исключения будет вариант, когда\n",
    "результат исключения отбрасывается а результатом становится \n",
    "результат правила регулярного паттерна.\n",
    "Это дает возможность не сломать уже имеющийся перевод из-за добавления исключений к грамматике.\n",
    "\n",
    "Вопрос дефолтного связывания паттернов с правилами допускает множество решений\n",
    "и остается открытым.\n",
    "В любом случае пользователь сможет создавать исключения паттернов и дополнительные правила,\n",
    "тем самым пополняя базу данных переводчика,\n",
    "а также менять связи паттернов с правилами для своего текста, сохранять эти связи,\n",
    "и применять к другим текстам.\n",
    "\n",
    "паттерн - набор альтернатив\n",
    "альтернатива - последовательность, с которой связан набор правил\n",
    "набор правил - набор правил + номер дефолтного правила\n",
    "\t\tили просто правило\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''англо-русский переводчик, основанный на правилах, с простым добавлением паттернов и правил\n",
    "\n",
    "en2ru\n",
    "decline\n",
    "p_noun\n",
    "p_noun1\n",
    "r_noun_comma_noun\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Паттерны и правила: Составные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Когда в правилах использовать S а когда один из классов Struct ?\n",
    "\n",
    "-S используется для неизменяемых узлов-листьев. Во всех остальных случаях используется один из классов Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from parse_system import S, SAttrs, ParseInfo, tokenizer, \\\n",
    "                        ch_title, ch_sentence, ch_anti_sentence, ch_open, \\\n",
    "                        seq, alt, p_alt, ELSE, W, D,\\\n",
    "                        warning, debug_pp\n",
    "import parse_system\n",
    "from classes import StC, StNum, StNoun, StVerb, I\n",
    "from ru_dictionary import ruwords, CW, add_runoun2, add_skl2, make_skl2\n",
    "from en_dictionary import dict_adj, dict_noun, dict_pronoun_ip, dict_pronoun_dp, \\\n",
    "                        dict_numeral, dict_verb, dict_verb_s, r_adj_noun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исключения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def r_A_noun(_a,_n): return StNoun([\n",
    "    I(maindep=_n,         attrs_from_left=_a)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_GOOD_MORNING(_g,_m):  return r_adj_noun(\n",
    "    CW('добрый',_g),\n",
    "    CW('утро',_m)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_SKAZHI_noun(_s,_p): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(vp=_p,   pad='vp')\n",
    "])\n",
    "def r_SKAZHI_phrase(_s,_p): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(nodep=_p)\n",
    "])\n",
    "def r_SKAZHI_c_phrase(_s,c,_p): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),#ruwords['сказать']\n",
    "    I(punct=c),\n",
    "    I(nodep=_p)\n",
    "])\n",
    "def r_SKAZHI_q_text(_s,q1,_p,q2): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(punct=q1, add_changers={ch_open}),\n",
    "    I(nodep=_p),\n",
    "    I(punct=q2),\n",
    "])\n",
    "def r_SKAZHI_c_q_text(_s,c,q1,_p,q2): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(punct=c),\n",
    "    I(punct=q1, add_changers={ch_open}),\n",
    "    I(nodep=_p),\n",
    "    I(punct=q2),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_U_noun_EST_noun(_n1_,_h_,_n2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ])),\n",
    "    I(nodep=S('есть',_h_.attrs)),\n",
    "    I(nodep=_n2_)\n",
    "])\n",
    "\n",
    "def r_U_noun_NET_noun(_n1_,_h_,_no_,_n2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ])),\n",
    "    I(nodep=S('нет',_h_.attrs)),\n",
    "    I(nodep=_n2_,        pad='rp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_noun_HAVE_noun(s,p):\n",
    "    p_HAVE_HAS = alt( W('have'), W('has') )\n",
    "    p_pronoun_dp = alt( D(dict_pronoun_dp), p_noun )\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun, p_HAVE_HAS,          p_pronoun_dp ],r_U_noun_EST_noun),\n",
    "        seq([ p_noun, p_HAVE_HAS, W('no'), p_pronoun_dp ],r_U_noun_NET_noun)\n",
    "#        seq([ p_noun, p_HAVE_HAS,          p_pronoun_dp ],r_noun_EST_U_noun),\n",
    "#        seq([ p_noun, p_HAVE_HAS, W('no'), p_pronoun_dp ],r_noun_NET_U_noun)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_numeral(s,p):\n",
    "    return D(dict_numeral)(s,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#2->\n",
    "@debug_pp\n",
    "def p_adj(s,p):\n",
    "    return D(dict_adj)(s,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Noun-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_noun_numeral(n,num): return StNoun([\n",
    "    I(maindep=n),\n",
    "    I(nomer=num)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_numeral_noun(num,n):\n",
    "    if num.chis!=n.chis :\n",
    "        warning('не совпадают числа числ. и сущ.:'+str(num)+str(n))\n",
    "    return StNum([\n",
    "        I(quantity=num,            chis=n.chis, rod=n.rod, odush=n.odush ),\n",
    "        I(maindep=n)\n",
    "    ],quantity=num.quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_noun_and_noun(sn,a,n):    return StNoun([\n",
    "    I(dep=sn),\n",
    "    I(nodep=S('и',a.attrs)),\n",
    "    I(dep=n)\n",
    "],c='mn', p='ip',o=False,r='m')\n",
    "def r_noun_comma_noun(sn,c,n):    return StNoun([\n",
    "    I(dep=sn),\n",
    "    I(punct=S(',',c.attrs)),\n",
    "    I(dep=n)\n",
    "],c='mn', p='ip',o=False,r='m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_adj_noun3(s,p): return p_alt(s,p,\n",
    "    seq([ alt(W('an'),ELSE,W('a')), p_noun3 ],r_A_noun),\n",
    "    seq([ W('good'), W('morning') ],r_GOOD_MORNING),             \n",
    "ELSE,\n",
    "    seq([ p_adj, p_noun3 ],r_adj_noun)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun3(s,p): return p_alt(s,p,\n",
    "    p_adj_noun3, #ELSE, # переход к следующему уровню\n",
    "    p_numeral,\n",
    "    D(dict_noun),\n",
    "    D(dict_pronoun_ip)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun2(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun3, p_numeral ], r_noun_numeral), #ELSE, # переход к следующему уровню\n",
    "    p_noun3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun1(s,p): return p_alt(s,p,\n",
    "    seq([ p_numeral, p_noun2 ], r_numeral_noun), #ELSE, # переход к следующему уровню\n",
    "    p_noun2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun1, W('and'), p_noun ],r_noun_and_noun  ),\n",
    "        seq([ p_noun1, W(',')  , p_noun ],r_noun_comma_noun),\n",
    "                 #ELSE, # переход к следующему уровню\n",
    "                 # идет конфликт с and-ом из глаголов\n",
    "        p_noun1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Существительные в разных формах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_noun_dp(_n): return StNoun([\n",
    "    I(maindep=_n,         pad='dp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_TO_noun_dp(_t,_n): return StNoun([\n",
    "    I(maindep=_n,         pad='dp', attrs_from_left=_t)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun_dp(s,p): return p_alt(s,p,\n",
    "    seq([D(dict_pronoun_dp)],r_noun_dp), \n",
    "    seq([ W('to'), p_noun ],r_TO_noun_dp)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb3: Сделать кому\n",
    "def r_verb_noun_dp_mn(_v,_n):    return StVerb([\n",
    "    I(maindep=_v, chis='mn'),\n",
    "    I(dp     =_n, pad='dp')\n",
    "])\n",
    "def r_NE_verb_noun_dp_mn(_v,no,_n):    return StVerb([\n",
    "    I(nodep  =S('не',no.attrs)),\n",
    "    I(maindep=_v, chis='mn'),\n",
    "    I(dp     =_n, pad='dp')\n",
    "])\n",
    "\n",
    "def r_verb_noun_dp_ed(_v_,_n_):     return StVerb([\n",
    "    I(maindep=_v_,  chis='ed'),\n",
    "    I(dp=_n_,       pad='dp')\n",
    "])\n",
    "def r_NE_verb_noun_dp_ed(_v,no,_n):    return StVerb([\n",
    "    I(nodep  =S('не',no.attrs)),\n",
    "    I(maindep=_v, chis='ed'),\n",
    "    I(dp     =_n, pad='dp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb2: сделать что\n",
    "def r_verb_noun(v,n): return StVerb([\n",
    "    I(maindep=v),\n",
    "    I(vp=n,   pad='vp')\n",
    "])\n",
    "def r_NE_verb_noun(v,no,n): return StVerb([\n",
    "    I(nodep=S('не',no.attrs)),\n",
    "    I(maindep=v),\n",
    "    I(vp=n,   pad='vp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb1: кто делает\n",
    "def r_to_verb(_t,_v): return StVerb([\n",
    "    I(maindep=_v,         form='neopr', attrs_from_left=_t)\n",
    "])\n",
    "\n",
    "def r_noun_verb(n,v): return StVerb([\n",
    "    I(ip=n),\n",
    "    I(main=v,   form='nast', pers=n.pers, chis=n.chis, rod=n.rod)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb1: кто (тоже) делает\n",
    "def r_noun_TOZHE_verb(_n, _v, _t): return StVerb([\n",
    "    I(ip=_n),\n",
    "    I(nodep=S('тоже',_t.attrs)),\n",
    "    I(main=_v,   form='nast', pers=_n.pers, chis=_n.chis, rod=_n.rod)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb: сделать одно и/но сделать сдругое\n",
    "def r_verb_NO_verb(_v1_,_c_,_but_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=_c_),\n",
    "    I(nodep=S('но',_c_.attrs)),\n",
    "    I(nodep=_v2_)\n",
    "])\n",
    "\n",
    "def r_verb_c_verb(_v1_,_c_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=_c_),\n",
    "    I(nodep=_v2_)\n",
    "])\n",
    "\n",
    "def r_verb_I_verb(_v1_,_i_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=S('и',_i_.attrs)),\n",
    "    I(nodep=_v2_)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb3: Сделать кому\n",
    "@debug_pp\n",
    "def p_verb3(s,p): return p_alt(s,p,\n",
    "    seq([ alt(D(dict_verb),D(dict_verb_s)),          p_noun_dp ],r_verb_noun_dp_ed),\n",
    "    seq([ alt(D(dict_verb),D(dict_verb_s)), W('no'), p_noun_dp ],r_NE_verb_noun_dp_ed),\n",
    "#    seq([ D(dict_verb_s), p_noun_dp ],r_verb_noun_dp_mn)\n",
    "    D(dict_verb),                                       \n",
    "    D(dict_verb_s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb2: сделать что\n",
    "@debug_pp\n",
    "def p_verb2(s,p): return p_alt(s,p,\n",
    "    #seq([ alt(W('say'),W('says')),                 p_phrase      ], r_SKAZHI_noun), \n",
    "       #ELSE, # исключение исключения\n",
    "    #seq([ alt(W('say'),W('says')),                 p_phrase      ], r_SKAZHI_phrase),\n",
    "    seq([ alt(W('say'),W('says')), W(':'),         p_phrase      ], r_SKAZHI_c_phrase),\n",
    "    seq([ alt(W('say'),W('says')),         W('\"'), p_text, W('\"')], r_SKAZHI_q_text),\n",
    "    seq([ alt(W('say'),W('says')), W(':'), W('\"'), p_text, W('\"')], r_SKAZHI_c_q_text), \n",
    "#ELSE,\n",
    "    seq([ p_verb3, p_noun ]         ,r_verb_noun),    #ELSE, # переход к следующему уровню\n",
    "    seq([ p_verb3, W('no'), p_noun ],r_NE_verb_noun),    #ELSE, # переход к следующему уровню\n",
    "    p_verb3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb1: кто делает\n",
    "@debug_pp\n",
    "def p_verb1_1(s,p): return p_alt(s,p,\n",
    "    pe_noun_HAVE_noun,                           \n",
    "ELSE,\n",
    "    seq([ p_noun, p_verb2 ],r_noun_verb),\n",
    "    seq([ W('to'), p_verb2 ],r_to_verb),   #ELSE, # переход к следующему уровню\n",
    "    p_verb2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb1: кто (тоже) делает\n",
    "@debug_pp\n",
    "def p_verb1(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun, p_verb1_1, W('too') ],r_noun_TOZHE_verb), #ELSE, # переход к следующему уровню\n",
    "    p_verb1_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb: сделать одно и/но сделать сдругое\n",
    "@debug_pp\n",
    "def p_verb(s,p): return p_alt(s,p,\n",
    "    seq([ p_verb1, W(','), p_verb1 ]          ,r_verb_c_verb),   \n",
    "    seq([ p_verb1, W(','), W('but'), p_verb1 ],r_verb_NO_verb),   \n",
    "    seq([ p_verb1, W('and'), p_verb1 ]        ,r_verb_I_verb),\n",
    "    #ELSE, # переход к следующему уровню\n",
    "    p_verb1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Фразы, предложения, текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_phrase(s,p): \n",
    "#    rezs=[]\n",
    "#    rezs+=p_verb(s,p)\n",
    "#    if len(rezs)>0: return rezs\n",
    "#    rezs+=p_noun(s,p)\n",
    "#    if len(rezs)>0: return rezs\n",
    "#    rezs+=p_noun_dp(s,p)\n",
    "#    if len(rezs)>0: return rezs\n",
    "#    rezs+=p_adj(s,p)\n",
    "#    return rezs\n",
    "    return p_alt(s,p,\n",
    "        p_verb,    #ELSE,\n",
    "        p_noun,    #ELSE,\n",
    "        p_noun_dp, #ELSE,\n",
    "        p_adj\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_proper={}# имена собственные\n",
    "@debug_pp\n",
    "def p_sentence(s,p):\n",
    "    first_capital = s[p]=='I' or ch_title in s[p].attrs.changers\n",
    "    def r_sentence(ph,d):\n",
    "        rez=StC([I(nodep=ph),I(punct=d)])\n",
    "        if first_capital: rez.attrs.changers|={ch_sentence}\n",
    "        return rez\n",
    "    restore_title=False\n",
    "    if ch_title in s[p].attrs.changers and s[p] not in dict_proper:\n",
    "        s[p].attrs.changers-={ch_title}\n",
    "        s[p].attrs.changers|={ch_anti_sentence}\n",
    "        restore_title=True\n",
    "    \n",
    "    rezs=seq([p_phrase,alt(W('.'),W('!'))],r_sentence)(s,p)\n",
    "    \n",
    "    if restore_title:\n",
    "        s[p].attrs.changers|={ch_title}\n",
    "        s[p].attrs.changers-={ch_anti_sentence}\n",
    "    return rezs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def maxlen_filter(patt,s,p):\n",
    "    '''находит самые длинные результаты, а остальные отбрасывает\n",
    "    \n",
    "    если самых длинных несколько - warning\n",
    "    '''\n",
    "    rezs=patt(s,p)\n",
    "    m=0\n",
    "    im=set()\n",
    "    for i in range(len(rezs)):\n",
    "        if rezs[i][0]>m:\n",
    "            m=rezs[i][0]\n",
    "            im={i}\n",
    "        elif rezs[i][0]==m:\n",
    "            im.add(i)\n",
    "    long_rezs= [rezs[i] for i in im]\n",
    "    if len(long_rezs)>1:\n",
    "        #print(p,m,s[p:m],SAttrs().join(s))\n",
    "        warning('multiple results:\\n'+\n",
    "            SAttrs().join(s[p:m])+'\\n'+\n",
    "            '\\n'.join(r.tostr() for void,r in long_rezs)\n",
    "        )\n",
    "            \n",
    "    return [] if len(long_rezs)==0 else long_rezs\n",
    "\n",
    "@debug_pp\n",
    "def p_text(s,p):\n",
    "    '''или последовательность предложений или 1 фраза\n",
    "    '''\n",
    "    rez=[]\n",
    "    while p<len(s):\n",
    "        rezs=maxlen_filter(p_sentence,s,p)\n",
    "        if len(rezs)==0: break\n",
    "        p1,r1=rezs[0] # отбрасываем остальные результаты\n",
    "        p=p1\n",
    "        rez.append(I(nodep=r1))\n",
    "    if len(rez)>0:\n",
    "        return [(p,StC(rez))]\n",
    "    else:\n",
    "        return maxlen_filter(p_phrase,s,p)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск и отладка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def _en2ru(s): # main\n",
    "    ''' (text|.)* + warning-и\n",
    "    '''\n",
    "    s=[ i for i in tokenizer(s)]\n",
    "    if len(s)==0:\n",
    "        warning('no tokens')\n",
    "        return ''\n",
    "    \n",
    "    ret_s = ''\n",
    "    p=0\n",
    "    while p<len(s):\n",
    "        #print('ITERATION',p)\n",
    "        rezs= p_text(s,p)\n",
    "        if len(rezs)==0:\n",
    "            warning(\"CAN'T TRANSLATE: \"+s[p])\n",
    "            ret_s += (' ' if p>0 else '')+ s[p]\n",
    "            p+=1\n",
    "        else:\n",
    "            p1,r1 = rezs[0] # отбрасываем остальные результаты\n",
    "            #print(p,p1,r1)\n",
    "            s1 = r1.tostr()\n",
    "            #print(p,p1,r1)\n",
    "            ret_s += (' ' if p>0 else '')+ s1\n",
    "            if p>0:\n",
    "                warning('TRANSLATION BREAKS: '+s1)\n",
    "            assert p1>p, rezs\n",
    "            p=p1\n",
    "    return ret_s\n",
    "\n",
    "def en2ru(s):\n",
    "    parse_system.DEBUGGING=False\n",
    "    return _en2ru(s)\n",
    "\n",
    "def d_en2ru(s):\n",
    "    l_d = parse_system.DEBUGGING\n",
    "    parse_system.DEBUGGING=True\n",
    "    r=_en2ru(s)\n",
    "    parse_system.DEBUGGING=l_d\n",
    "    return r\n",
    "\n",
    "def pr_en2ru(s):\n",
    "    print(\"'''\"+en2ru(s)+\"'''\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def decline(s,pads=['ip','rp','dp','vp','tp','pp']):\n",
    "    s=[ i for i in tokenizer(s)]\n",
    "    # добавить дочитывание точки и остаточных пробелов\n",
    "    rezs=[res for pos,res in p_noun(s,0) if pos==len(s)]\n",
    "    if len(rezs)!=1:\n",
    "        raise TextError(rezs)\n",
    "    tmp=rezs[0]\n",
    "    \n",
    "    m=[]\n",
    "    for p in pads:\n",
    "        #print(str(tmp))\n",
    "        prompt= \\\n",
    "            '' if p=='ip' else\\\n",
    "            'нет ' if p=='rp' else\\\n",
    "            'дать ' if p=='dp' else\\\n",
    "            'вижу ' if p=='vp' else\\\n",
    "            'творю ' if p=='tp' else\\\n",
    "            'думаю о ' if p=='pp' else\\\n",
    "            throw(ValueError('bad pad: '+p))\n",
    "        #rez=deepcopy(tmp)\n",
    "        tmp.pad=p\n",
    "        m.append(prompt+tmp.tostr())#        print(prompt+str(tmp))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def _parse_pat(patt,s):\n",
    "    s=[ i for i in tokenizer(s)]\n",
    "    return patt(s,0)\n",
    "\n",
    "def parse_pat(patt,s):\n",
    "    parse_system.DEBUGGING=False\n",
    "    return _parse_pat(patt,s)\n",
    "\n",
    "def d_parse_pat(patt,s):\n",
    "    l_d = parse_system.DEBUGGING\n",
    "    parse_system.DEBUGGING=True\n",
    "    r=parsepat(s,patt)\n",
    "    parse_system.DEBUGGING=l_d\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scheme(s,full=False):\n",
    "    s=[ i for i in tokenizer(s)]\n",
    "    ParseInfo.enabled = True\n",
    "    rezs=maxlen_filter(p_text,s,0)\n",
    "    ParseInfo.enabled = False\n",
    "    for end,rez in rezs:\n",
    "        if 0:\n",
    "            def print_rez0(rez,depth):\n",
    "                info = rez.parse_info\n",
    "                if hasattr(info,'p_start'):\n",
    "                    print('  '*depth+' '+SAttrs().join( s[info.p_start : info.p_end] ))\n",
    "                if hasattr(info,'patterns') or hasattr(info,'rule_group'):\n",
    "                    if hasattr(info,'patterns'):\n",
    "                        #'<'+str(id(info.patterns))+'>'+\n",
    "                        patterns = ' '.join(info.patterns) if full else info.patterns[0]\n",
    "                    else:\n",
    "                        patterns = ''\n",
    "                    if hasattr(info,'rule_group'):\n",
    "                        if type(info.rule_group)==list:\n",
    "                            assert info.rule_group[0]!=0\n",
    "                            rule = info.rule_group[info.rule_group[0]]\n",
    "                            rules = str(info.rule_group[0])+'/'+str(len(info.rule_group)-1)+' '\n",
    "                        else:\n",
    "                            rule = info.rule_group\n",
    "                            rules = ''\n",
    "                        rules += (rule.__name__ if callable(rule) else str(rule))\n",
    "                    else:\n",
    "                        rules = ''\n",
    "                    print('  '*depth +' '+ patterns+' -> '+rules)\n",
    "                print('  '*depth+'*'+str(rez))\n",
    "\n",
    "                if hasattr(rez,'talk'):\n",
    "                    for x in rez.talk:\n",
    "                        print_rez0(x[1],depth+1)\n",
    "        \n",
    "            rez.pull_deferred()\n",
    "            print_rez0(rez,0)\n",
    "        \n",
    "        class Node:\n",
    "            __slots__ = ['childs','p_start','p_end','patterns','rule','rez']\n",
    "        def make_tree(struct):\n",
    "            if hasattr(struct,'talk'):\n",
    "                if hasattr(struct.parse_info,'p_start'):\n",
    "                    info = struct.parse_info\n",
    "                    node = Node()\n",
    "                    node.p_start = info.p_start\n",
    "                    node.p_end = info.p_end\n",
    "                    node.patterns = info.patterns\n",
    "                    if hasattr(info,'rule_group'):\n",
    "                        if type(info.rule_group)==list:\n",
    "                            assert info.rule_group[0]!=0\n",
    "                            rule = info.rule_group[info.rule_group[0]]\n",
    "                            rules = str(info.rule_group[0])+'/'+str(len(info.rule_group)-1)+' '\n",
    "                        else:\n",
    "                            rule = info.rule_group\n",
    "                            rules = ''\n",
    "                        node.rule = rules + (rule.__name__ if callable(rule) else str(rule))\n",
    "                    else:\n",
    "                        node.rule = ''\n",
    "                    node.rez = struct\n",
    "                    node.childs = []\n",
    "                    depth = 0\n",
    "                    for tup in struct.talk:\n",
    "                        d,m = make_tree(tup[1])\n",
    "                        if d>depth: depth = d\n",
    "                        node.childs+=m\n",
    "                    node.childs.sort(key=lambda node:node.p_start)\n",
    "                    return (depth+1,[node])\n",
    "                else:\n",
    "                    mm = []\n",
    "                    depth = 0\n",
    "                    for tup in struct.talk:\n",
    "                        d,m = make_tree(tup[1])\n",
    "                        if d>depth: depth = d\n",
    "                        mm+=m\n",
    "                    return (depth,mm)\n",
    "            elif hasattr(struct.parse_info,'p_start'):\n",
    "                info = struct.parse_info\n",
    "                node = Node()\n",
    "                node.p_start = info.p_start\n",
    "                node.p_end = info.p_end\n",
    "                node.patterns = info.patterns\n",
    "                if hasattr(info,'rule_group'):\n",
    "                    if type(info.rule_group)==list:\n",
    "                        assert info.rule_group[0]!=0\n",
    "                        rule = info.rule_group[info.rule_group[0]]\n",
    "                        rules = str(info.rule_group[0])+'/'+str(len(info.rule_group)-1)+' '\n",
    "                    else:\n",
    "                        rule = info.rule_group\n",
    "                        rules = ''\n",
    "                    node.rule = rules + (rule.__name__ if callable(rule) else str(rule))\n",
    "                else:\n",
    "                    node.rule = ''\n",
    "                node.rez = struct\n",
    "                node.childs = []\n",
    "                return (1,[node])\n",
    "            else:\n",
    "                return (0,[])\n",
    "        \n",
    "        if 0:\n",
    "            def print_rez1(info,depth):\n",
    "                if hasattr(info,'p_start'):\n",
    "                    print('  '*depth+' '+SAttrs().join( s[info.p_start : info.p_end] ))\n",
    "                patterns = ' '.join(info.patterns) if full else info.patterns[0]\n",
    "                print('  '*depth +' '+ patterns+' -> '+info.rule)\n",
    "                print('  '*depth+'*'+str(info.rez))\n",
    "\n",
    "                if hasattr(info,'childs'):\n",
    "                    for x in info.childs:\n",
    "                        print_rez1(x,depth+1)\n",
    "                    \n",
    "            rez.pull_deferred()\n",
    "            \n",
    "        depth,mm = make_tree(rez)\n",
    "        assert len(mm)==1\n",
    "        tree=mm[0]\n",
    "        \n",
    "        if 0:\n",
    "            print('depth=',depth)\n",
    "            print_rez1(tree,0)\n",
    "        \n",
    "        DISTANCE = 2\n",
    "        cols = []\n",
    "        pos=0\n",
    "        for word in s:\n",
    "            cols.append(pos)\n",
    "            pos+=len(word)+DISTANCE\n",
    "        cols.append(pos)\n",
    "        \n",
    "        class Line:\n",
    "            __slots__=['h','line']\n",
    "            def __init__(self,h,l):\n",
    "                self.h = h\n",
    "                self.line = l\n",
    "                \n",
    "        lines = [Line(0,[None for i in range(len(s))]) for j in range(depth)]\n",
    "        def make_lines(node):\n",
    "            dd=0\n",
    "            for c in node.childs:\n",
    "                d = make_lines(c)\n",
    "                if d>dd: dd = d\n",
    "                    \n",
    "            node.rez = node.rez.tostr()\n",
    "            for i in range(1,len(node.patterns)):\n",
    "                node.patterns[i] = '('+node.patterns[i]+')'\n",
    "            \n",
    "            if len(node.patterns)>lines[dd].h: lines[dd].h = len(node.patterns)\n",
    "                \n",
    "            maxlen = max(len(node.rule),len(node.rez),max([len(i) for i in node.patterns]))\n",
    "            dlen = (maxlen+DISTANCE) - (cols[node.p_end]-cols[node.p_start])\n",
    "            #print(node.rez,maxlen,dlen)\n",
    "            if dlen>0:\n",
    "                for i in range(node.p_end,len(cols)):\n",
    "                    cols[i]+=dlen\n",
    "            \n",
    "            lines[dd].line[node.p_start] = node\n",
    "            return dd+1\n",
    "        dd = make_lines(tree)\n",
    "        assert dd==depth\n",
    "        \n",
    "        def inde(s,p_start,p_end):\n",
    "            return s+' '*(cols[p_end]-cols[p_start]-len(s))\n",
    "        \n",
    "        for i in range(len(s)):\n",
    "            print(inde(s[i],i,i+1),end='')\n",
    "        print()\n",
    "        \n",
    "        for line_ in lines:\n",
    "            line=line_.line\n",
    "            \n",
    "            # _______\n",
    "            i=0\n",
    "            l=''\n",
    "            while i<len(s):\n",
    "                if line[i]==None:\n",
    "                    l+=inde('',i,i+1)\n",
    "                    i+=1\n",
    "                else:\n",
    "                    l+='_'*(cols[line[i].p_end]-cols[line[i].p_start]-DISTANCE)+' '*DISTANCE\n",
    "                    i=line[i].p_end\n",
    "            print(l)\n",
    "            \n",
    "            # patterns[0]\n",
    "            i=0\n",
    "            l=''\n",
    "            while i<len(s):\n",
    "                if line[i]==None:\n",
    "                    l+=inde('',i,i+1)\n",
    "                    i+=1\n",
    "                else:\n",
    "                    l+=inde(line[i].patterns[0],line[i].p_start,line[i].p_end)\n",
    "                    i=line[i].p_end\n",
    "            print(l)\n",
    "\n",
    "            # rule\n",
    "            i=0\n",
    "            l=''\n",
    "            while i<len(s):\n",
    "                if line[i]==None:\n",
    "                    l+=inde('',i,i+1)\n",
    "                    i+=1\n",
    "                else:\n",
    "                    l+=inde(line[i].rule,line[i].p_start,line[i].p_end)\n",
    "                    i=line[i].p_end\n",
    "            print(l)\n",
    "\n",
    "            # rez\n",
    "            i=0\n",
    "            l=''\n",
    "            while i<len(s):\n",
    "                if line[i]==None:\n",
    "                    l+=inde('',i,i+1)\n",
    "                    i+=1\n",
    "                else:\n",
    "                    l+=inde(line[i].rez,line[i].p_start,line[i].p_end)\n",
    "                    i=line[i].p_end\n",
    "            print(l)\n",
    "            \n",
    "            if full:\n",
    "                for j in range(1,line_.h):\n",
    "                    # patterns[j]\n",
    "                    i=0\n",
    "                    l=''\n",
    "                    while i<len(s):\n",
    "                        if line[i]==None or j>=len(line[i].patterns):\n",
    "                            l+=inde('',i,i+1)\n",
    "                            i+=1\n",
    "                        else:\n",
    "                            l+=inde(line[i].patterns[j],line[i].p_start,line[i].p_end)\n",
    "                            i=line[i].p_end\n",
    "                    print(l)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "    КОДИТЬ И ДЕБАЖИТЬ ТЕКУЩЕЕ\n",
    "    9)  (находится) на/в\n",
    "    10) вопросы-ответы\n",
    "        считать от до\n",
    "        ловить\n",
    "    11) сколько\n",
    "    13) где\n",
    "    14) какого цвета\n",
    "        КОНТЕКСТ\n",
    "    15) посмотри\n",
    "\n",
    "копирование и подтягивание в отладке паттернов\n",
    "отладка правил\n",
    "\n",
    "автовыбор склонений/спряжений для существительных с одним числом, прилагательных и глаголов\n",
    "регламентировать использование attrs-ов в правилах и только потом приступать к контекстам\n",
    "сделать устранение конфликтов исключений\n",
    "\n",
    "на потом: \n",
    "\tзадание глобального контекста (задание дефолтных правил)\n",
    "\tвыбор паттернов и правил в зависимости от времени \n",
    "\n",
    "работа с деревом вглубь:\n",
    "\tпросмотр вглубь возможен\n",
    "\t\n",
    "\tу каждого узла ссылка на правило и его аргументы\n",
    "\t\t- как был получен этот узел\n",
    "\t... у каждого узла ссылка на паттерн и позицию - во враппере\n",
    "\t\tа также номер альтернативы - в seq\n",
    "\t\tили ссылка на группу правил\n",
    "\tв узлах дерева поля \n",
    "\t\tcontext_dep\n",
    "\t\t\tTrue - узел зависит от контекста\n",
    "\t\t\t\tссылка на правило, также принимат контекст\n",
    "\t\t\tFalse - узел не зависит от контекста\n",
    "\t\tcontect_dep_srcs - массив номеров - \n",
    "\t\t\tкакие аргументы правила зависят от контекста (или их потомки зависят от контекста)\n",
    "\t\t\tт.е. какие аргументы правила требую ремейка в случае изменения контекста\n",
    "\t\t\t\n",
    "\t\tcontext(может отсутствовать) - словарь (строка, ссылка на узел), который является контекстом\n",
    "\t\t\t- устанавливается в правилах\n",
    "\tфункция context_remake(node,context)\n",
    "\n",
    "watch, двое, трое, пятеро\n",
    "\n",
    "написать везде строки документации\n",
    "написать инструкцию как пользоваться\n",
    "\n",
    "...\n",
    "открывающиеся кавычки\n",
    "\n",
    "для больших текстов p_sentence будет делать срез со своей позции до конца\n",
    "    - чтобы обновить кэши ф-ций\n",
    "\n",
    "исключения парсить, если регулярным образом распарсилось\n",
    "    каждая функция будет с аргументом: парсить или нет исключения\n",
    "\n",
    "атрибуты слов: (теги)\n",
    "отображение открывающейся кавычки (SAttrs.join)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decline('two watches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я вижу джем и одну чашку.'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('I see jam and one cup.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Скажите информацию'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('Say information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSLATION BREAKS: \n",
      "Эта рыба является\n",
      "CAN'T TRANSLATE: on\n",
      "TRANSLATION BREAKS: определённное блюдо.\n",
      "'''У этой девочки есть рыба. \n",
      "Эта рыба является on определённное блюдо.'''\n"
     ]
    }
   ],
   "source": [
    "pr_en2ru('''This girl has a fish.\n",
    "This fish is on the dish.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAN'T TRANSLATE: dolls\n",
      "CAN'T TRANSLATE: .\n",
      "TRANSLATION BREAKS: У\n",
      "этого мальчика есть два мяча. У\n",
      "той девочки есть пять книг. У\n",
      "того мальчика есть четыре ручки.\n",
      "'''у Этой девочки есть три dolls . У\n",
      "этого мальчика есть два мяча. У\n",
      "той девочки есть пять книг. У\n",
      "того мальчика есть четыре ручки.'''\n"
     ]
    }
   ],
   "source": [
    "pr_en2ru('''This girl has three dolls.\n",
    "This boy has two balls.\n",
    "That girl has five books.\n",
    "That boy has four pens.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boy          has  two           balls      \n",
      "___________       ____________  _________  \n",
      "dict_noun         dict_numeral  dict_noun  \n",
      "2/2 мальчик       два           мячи       \n",
      "мальчик           два           мячи       \n",
      "(p_noun3)         (p_numeral)   (p_noun3)  \n",
      "(p_noun2)                       (p_noun2)  \n",
      "(p_noun1)                                  \n",
      "(p_noun)                                   \n",
      "                  _______________________  \n",
      "                  p_noun1                  \n",
      "                  r_numeral_noun           \n",
      "                  два мяча                 \n",
      "                  (p_noun)                 \n",
      "_________________________________________  \n",
      "pe_noun_HAVE_noun                          \n",
      "r_U_noun_EST_noun                          \n",
      "у мальчика есть два мяча                   \n",
      "(__ELSE__)                                 \n",
      "(p_verb1_1)                                \n",
      "(p_verb1)                                  \n",
      "(p_verb)                                   \n",
      "(p_phrase)                                 \n",
      "(p_text)                                   \n"
     ]
    }
   ],
   "source": [
    "parse_scheme('boy has two balls',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  boy          has  two           balls      \n",
      "   ___________       ____________  _________  \n",
      "   dict_noun         dict_numeral  dict_noun  \n",
      "   2/2 мальчик       два           мячи       \n",
      "   мальчик           два           мячи       \n",
      "______________       _______________________  \n",
      "__ELSE__             p_noun1                  \n",
      "r_A_noun             r_numeral_noun           \n",
      "мальчик              два мяча                 \n",
      "____________________________________________  \n",
      "pe_noun_HAVE_noun                             \n",
      "r_U_noun_EST_noun                             \n",
      "у мальчика есть два мяча                      \n"
     ]
    }
   ],
   "source": [
    "parse_scheme('a boy has two balls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'два мяча'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('two balls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say  :  \"  seven         ,  six           ,  four          ,  two           ,  five          ,  three         ,  one           .  \"  \n",
      "           ____________     ____________     ____________     ____________     ____________     ____________     ____________        \n",
      "           dict_numeral     dict_numeral     dict_numeral     dict_numeral     dict_numeral     dict_numeral     dict_numeral        \n",
      "           семь             шесть            четыре           два              пять             три              один                \n",
      "           Семь             шесть            четыре           два              пять             три              один                \n",
      "                                                                                                _____________________________        \n",
      "                                                                                                p_noun                               \n",
      "                                                                                                r_noun_comma_noun                    \n",
      "                                                                                                три, один                            \n",
      "                                                                               ______________________________________________        \n",
      "                                                                               p_noun                                                \n",
      "                                                                               r_noun_comma_noun                                     \n",
      "                                                                               пять, три, один                                       \n",
      "                                                              _______________________________________________________________        \n",
      "                                                              p_noun                                                                 \n",
      "                                                              r_noun_comma_noun                                                      \n",
      "                                                              два, пять, три, один                                                   \n",
      "                                             ________________________________________________________________________________        \n",
      "                                             p_noun                                                                                  \n",
      "                                             r_noun_comma_noun                                                                       \n",
      "                                             четыре, два, пять, три, один                                                            \n",
      "                            _________________________________________________________________________________________________        \n",
      "                            p_noun                                                                                                   \n",
      "                            r_noun_comma_noun                                                                                        \n",
      "                            шесть, четыре, два, пять, три, один                                                                      \n",
      "           __________________________________________________________________________________________________________________        \n",
      "           p_noun                                                                                                                    \n",
      "           r_noun_comma_noun                                                                                                         \n",
      "           Семь, шесть, четыре, два, пять, три, один                                                                                 \n",
      "           _____________________________________________________________________________________________________________________     \n",
      "           p_sentence                                                                                                                \n",
      "           r_sentence                                                                                                                \n",
      "           Семь, шесть, четыре, два, пять, три, один.                                                                                \n",
      "           _____________________________________________________________________________________________________________________     \n",
      "           p_text                                                                                                                    \n",
      "                                                                                                                                     \n",
      "           Семь, шесть, четыре, два, пять, три, один.                                                                                \n",
      "___________________________________________________________________________________________________________________________________  \n",
      "p_verb2                                                                                                                              \n",
      "r_SKAZHI_c_q_text                                                                                                                    \n",
      "Скажите:\" Семь, шесть, четыре, два, пять, три, один.\"                                                                                \n"
     ]
    }
   ],
   "source": [
    "parse_scheme('Say: \"Seven, six, four, two, five, three, one.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_en2ru('''The girl has one dish.\n",
    "She has two spoons.\n",
    "The boy has three sticks.\n",
    "He has five stars.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_en2ru('''This frog is on the log.\n",
    "That frog is in the lake.\n",
    "The snake is in the box.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_en2ru('''The spoon is in the cup.\n",
    "The squirrel is on the log.\n",
    "The doll is on the bed.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
