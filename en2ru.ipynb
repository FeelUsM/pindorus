{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "p_паттерн парсит текст (str, pos), \n",
    "    вызывая другие паттерны, возвращающие древовидные структуры\n",
    "    эти древовидные структуры передает одному из правил\n",
    "        (остальные вызовы правил закомментированы \n",
    "            - в рамках одного текста каждый паттерн имеет ровно 1 смысл)\n",
    "    и возвращает (pos, результат этого правила), помещенный в массив\n",
    "    \n",
    "    /*пока на ошибках парсинга концентрировать не будем*/\n",
    "    если ничего не удалось распарсить, ???возвращаемый массив будет пустым???\n",
    "    если удалось распарсить несколько вариантов - в массиве будет насколько вариантов\n",
    "        сначала парсятся все исключения\n",
    "        потом парсятся все обычные варианты (если нет исключений)\n",
    "```\n",
    "\n",
    "```\n",
    "r_правило получает список древовидных структур\n",
    "    обрабатывает их по определенному правилу\n",
    "    возвращает древовидную структуру\n",
    "```\n",
    "\n",
    "```\n",
    "древовидная структура - map, со следующими ключами\n",
    "    type: 'noun'/'adj'/'verb'/'num'/... - определяем через isinstance()\n",
    "    постоянные параметры (для сущ.: род, число)\n",
    "    переменные параметры (для сущ.: падеж)\n",
    "    talk: массив древовидных структур\n",
    "        или пар (тип, слово), где тип - main/punct/other\n",
    "```\n",
    "\n",
    "```\n",
    "str(древовидная структура)\n",
    "    превращает древовидную структуру в строку\n",
    "```\n",
    "\n",
    "```\n",
    "для каждого типа элемента древовидной структуры будет map\n",
    "    где каждой строке (для сущ. - слово в и.п.) будет соответствовать\n",
    "        структура данных, которая вместе в переменными параметрами передается в \n",
    "        sh_функция для этого типа элемента древовидной структуры\n",
    "            которая будет возвращать слово в соотв. форме (для сущ. в соотв. падеже)\n",
    "```\n",
    "---\n",
    "```\n",
    "В дальнейшем предполагается, что паттерны и правила будут писать пользователи\n",
    "грамматика не преобразовывается в LL(1) или какой-то другой промежуточный формат,\n",
    "а парсится как есть, с возвратами (LL(*)), по этому результаты нетерминалов кэшируются.\n",
    "Также стоит защита от зацикливания.\n",
    "Никто не обещал, что грамматика будет однозначной, \n",
    "поэтому каждый нетерминал возвращает массив результатов.\n",
    "Но в конечном итоге таких результатов должно быть немного.\n",
    "Ситуация, когда получаются одинаковые результаты явлется нежелательной.\n",
    "\n",
    "В дальнейшем предполагается, что будет центральная грамматика, \n",
    "а у ее правил пользователи будут создавать исключения.\n",
    "Паттерн A является исключением паттерна B, если \n",
    "всё что может разобрать паттерн A может разобрать паттерн B,\n",
    "т.е. A задает подъязык языка B, \n",
    "т.е. A является частным случаем B (но связано с другим правилом).\n",
    "Сначала парсится B, и если это оказалось удачным, парсится A.\n",
    "Если А распарсилось неудачно, то результатом станосится результат B,\n",
    "а если удачно - то результат B отбрасывается и результатом станосится результат A.\n",
    "\n",
    "В дальнейшем предполагается возможность каждый паттерн связывать с \n",
    "набором правил, а точнее с одним правилом из заданного набора.\n",
    "А также возможность эти наборы пополнять.\n",
    "Одним из правил перевода исключения будет вариант, когда\n",
    "результат исключения отбрасывается а результатом становится \n",
    "результат правила регулярного паттерна.\n",
    "Это дает возможность не сломать уже имеющийся перевод из-за добавления исключений к грамматике.\n",
    "\n",
    "Вопрос дефолтного связывания паттернов с правилами допускает множество решений\n",
    "и остается открытым.\n",
    "В любом случае пользователь сможет создавать исключения паттернов и дополнительные правила,\n",
    "тем самым пополняя базу данных переводчика,\n",
    "а также менять связи паттернов с правилами для своего текста, сохранять эти связи,\n",
    "и применять к другим текстам.\n",
    "\n",
    "паттерн - набор альтернатив\n",
    "альтернатива - последовательность, с которой связан набор правил\n",
    "набор правил - набор правил + номер дефолтного правила\n",
    "\t\tили просто правило\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''англо-русский переводчик, основанный на правилах, с простым добавлением паттернов и правил\n",
    "\n",
    "en2ru\n",
    "decline\n",
    "p_noun\n",
    "p_noun1\n",
    "r_noun_comma_noun\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from parse_system import S, SAttrs, tokenizer, \\\n",
    "                        ch_title, ch_sentence, ch_anti_sentence, ch_open, \\\n",
    "                        seq, alt, p_alt, ELSE, W, D\n",
    "from classes import StC, StNum, StNoun, StVerb, I\n",
    "from ru_dictionary import ruwords, CW, add_runoun2, add_skl2, make_skl2\n",
    "from en_dictionary import dict_adj, dict_noun, dict_pronoun_ip, dict_pronoun_dp, \\\n",
    "                        dict_numeral, dict_verb, dict_verb_s, r_adj_noun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_warning(s): \n",
    "    print(s)\n",
    "warning = default_warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Паттерны и правила: Составные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "## паттерны\n",
    "\n",
    "## парвила\n",
    "\n",
    "## классы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUGGING=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def debug_pp(fun):\n",
    "    s_point=[] # когда изменяется s - означает, что нужно сбросить кэш\n",
    "    cache={}\n",
    "    def wrapper(s,p):\n",
    "        nonlocal s_point,cache\n",
    "        if not(s is s_point):\n",
    "            s_point=s\n",
    "            cache={}\n",
    "        if DEBUGGING:\n",
    "            debug_s = '.'*p+'*'+'.'*(len(s)-p-1)+(' ' if p<len(s) else '')+\\\n",
    "                fun.__name__+'___'+str(p)\n",
    "        if p in cache:\n",
    "            if DEBUGGING: print('|'+debug_s)\n",
    "            if cache[p]==None:\n",
    "                raise ParseError('зацикливание '+fun.__name__+'(s,'+p+')')\n",
    "            return cache[p]\n",
    "        else:\n",
    "            if DEBUGGING: print('{'+debug_s)\n",
    "        \n",
    "        cache[p]=None\n",
    "        rezs=fun(s,p)\n",
    "        cache[p]=rezs\n",
    "        \n",
    "        if DEBUGGING:\n",
    "            print('}'+debug_s)\n",
    "            for p1,r1 in rezs:\n",
    "                print('-'+'.'*p+'_'*(p1-p)+'.'*(len(s)-p1)+' '+\\\n",
    "                     str(r1))\n",
    "            \n",
    "#            print('_'+'.'*p+str(len(rezs)),'in ',fun.__name__,'}',\n",
    "#                  [(p,str(r)) for (p,r) in rezs],'\\n')\n",
    "#            for i in rezs:\n",
    "#                if isinstance(i[1],StDeclinable):\n",
    "#                    i[1].check_attrs('wrapper:'+fun.__name__)\n",
    "        \n",
    "        return rezs\n",
    "    return wrapper\n",
    "    return fun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исключения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def r_A_noun(_a,_n): return StNoun([\n",
    "    I(maindep=_n,         attrs_from_left=_a)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_GOOD_MORNING(_g,_m):  return r_adj_noun(\n",
    "    CW('добрый',_g),\n",
    "    CW('утро',_m)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_SKAZHI_noun(_s,_p): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(vp=_p,   pad='vp')\n",
    "])\n",
    "def r_SKAZHI_phrase(_s,_p): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(nodep=_p)\n",
    "])\n",
    "def r_SKAZHI_c_phrase(_s,c,_p): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),#ruwords['сказать']\n",
    "    I(punct=c),\n",
    "    I(nodep=_p)\n",
    "])\n",
    "def r_SKAZHI_q_text(_s,q1,_p,q2): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(punct=q1, add_changers={ch_open}),\n",
    "    I(nodep=_p),\n",
    "    I(punct=q2),\n",
    "])\n",
    "def r_SKAZHI_c_q_text(_s,c,q1,_p,q2): return StVerb([\n",
    "    I(maindep=CW('сказать',_s)),\n",
    "    I(punct=c),\n",
    "    I(punct=q1, add_changers={ch_open}),\n",
    "    I(nodep=_p),\n",
    "    I(punct=q2),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_U_noun_EST_noun(_n1_,_h_,_n2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ])),\n",
    "    I(nodep=S('есть',_h_.attrs)),\n",
    "    I(nodep=_n2_)\n",
    "])\n",
    "\n",
    "def r_U_noun_NET_noun(_n1_,_h_,_no_,_n2_):    return StC([\n",
    "    I(nodep=StC([\n",
    "        I(nodep=S('у')),\n",
    "        I(nodep=_n1_,   pad='rp', npad='n' )# у Него\n",
    "    ])),\n",
    "    I(nodep=S('нет',_h_.attrs)),\n",
    "    I(nodep=_n2_,        pad='rp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def pe_HAVE_noun(s,p):\n",
    "    p_HAVE_HAS = alt( W('have'), W('has') )\n",
    "    p_pronoun_dp = alt( D(dict_pronoun_dp), p_noun )\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun, p_HAVE_HAS,          p_pronoun_dp ],r_U_noun_EST_noun),\n",
    "        seq([ p_noun, p_HAVE_HAS, W('no'), p_pronoun_dp ],r_U_noun_NET_noun)\n",
    "#        seq([ p_noun, p_HAVE_HAS,          p_pronoun_dp ],r_noun_EST_U_noun),\n",
    "#        seq([ p_noun, p_HAVE_HAS, W('no'), p_pronoun_dp ],r_noun_NET_U_noun)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_numeral(s,p):\n",
    "    return D(dict_numeral)(s,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2->\n",
    "@debug_pp\n",
    "def p_adj(s,p):\n",
    "    return D(dict_adj)(s,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_adj_noun3(s,p): return p_alt(s,p,\n",
    "    seq([ alt(W('an'),ELSE,W('a')), p_noun3 ],r_A_noun),\n",
    "    #seq([ alt(W('an'),ELSE,W('a')), p_noun3 ],r_NEKOTORYJ_noun),\n",
    "    seq([ W('good'), W('morning') ],r_GOOD_MORNING),             \n",
    "ELSE,\n",
    "    seq([ p_adj, p_noun3 ],r_adj_noun)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun3(s,p): return p_alt(s,p,\n",
    "    p_adj_noun3, #ELSE, # переход к следующему уровню\n",
    "    p_numeral,\n",
    "    D(dict_noun),\n",
    "    D(dict_pronoun_ip)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def r_noun_numeral(n,num): return StNoun([\n",
    "    I(maindep=n),\n",
    "    I(nomer=num)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun2(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun3, p_numeral ], r_noun_numeral), #ELSE, # переход к следующему уровню\n",
    "    p_noun3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def r_numeral_noun(num,n):\n",
    "    if num.chis!=n.chis :\n",
    "        warning('не совпадают числа числ. и сущ.:'+str(num)+str(n))\n",
    "    return StNum([\n",
    "        I(quantity=num,            chis=n.chis, rod=n.rod, odush=n.odush ),\n",
    "        I(maindep=n)\n",
    "    ],quantity=num.quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun1(s,p): return p_alt(s,p,\n",
    "    seq([ p_numeral, p_noun2 ], r_numeral_noun), #ELSE, # переход к следующему уровню\n",
    "    p_noun2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def r_noun_and_noun(sn,a,n):    return StNoun([\n",
    "    I(dep=sn),\n",
    "    I(nodep=S('и',a.attrs)),\n",
    "    I(dep=n)\n",
    "],c='mn', p='ip',o=False,r='m')\n",
    "def r_noun_comma_noun(sn,c,n):    return StNoun([\n",
    "    I(dep=sn),\n",
    "    I(punct=S(',',c.attrs)),\n",
    "    I(dep=n)\n",
    "],c='mn', p='ip',o=False,r='m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun(s,p):\n",
    "    return p_alt(s,p,\n",
    "        seq([ p_noun1, W('and'), p_noun ],r_noun_and_noun  ),\n",
    "        seq([ p_noun1, W(',')  , p_noun ],r_noun_comma_noun),\n",
    "                 #ELSE, # переход к следующему уровню\n",
    "                 # идет конфликт с and-ом из глаголов\n",
    "        p_noun1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def r_noun_dp(_n): return StNoun([\n",
    "    I(maindep=_n,         pad='dp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def r_TO_noun_dp(_t,_n): return StNoun([\n",
    "    I(maindep=_n,         pad='dp', attrs_from_left=_t)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_noun_dp(s,p): return p_alt(s,p,\n",
    "    seq([D(dict_pronoun_dp)],r_noun_dp), \n",
    "    seq([ W('to'), p_noun ],r_TO_noun_dp)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb-like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verb3:  Сделать кому"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_verb_noun_dp_mn(_v,_n):    return StVerb([\n",
    "    I(maindep=_v, chis='mn'),\n",
    "    I(dp     =_n, pad='dp')\n",
    "])\n",
    "def r_NE_verb_noun_dp_mn(_v,no,_n):    return StVerb([\n",
    "    I(nodep  =S('не',no.attrs)),\n",
    "    I(maindep=_v, chis='mn'),\n",
    "    I(dp     =_n, pad='dp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_verb_noun_dp_ed(_v_,_n_):     return StVerb([\n",
    "    I(maindep=_v_,  chis='ed'),\n",
    "    I(dp=_n_,       pad='dp')\n",
    "])\n",
    "def r_NE_verb_noun_dp_ed(_v,no,_n):    return StVerb([\n",
    "    I(nodep  =S('не',no.attrs)),\n",
    "    I(maindep=_v, chis='ed'),\n",
    "    I(dp     =_n, pad='dp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_verb3(s,p): return p_alt(s,p,\n",
    "    seq([ alt(D(dict_verb),D(dict_verb_s)),          p_noun_dp ],r_verb_noun_dp_ed),\n",
    "    seq([ alt(D(dict_verb),D(dict_verb_s)), W('no'), p_noun_dp ],r_NE_verb_noun_dp_ed),\n",
    "#    seq([ D(dict_verb_s), p_noun_dp ],r_verb_noun_dp_mn)\n",
    "    D(dict_verb),                                       \n",
    "    D(dict_verb_s)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verb2: сделать что"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_verb_noun(v,n): return StVerb([\n",
    "    I(maindep=v),\n",
    "    I(vp=n,   pad='vp')\n",
    "])\n",
    "def r_NE_verb_noun(v,no,n): return StVerb([\n",
    "    I(nodep=S('не',no.attrs)),\n",
    "    I(maindep=v),\n",
    "    I(vp=n,   pad='vp')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_verb2(s,p): return p_alt(s,p,\n",
    "    seq([ alt(W('say'),W('says')),                 p_phrase      ], r_SKAZHI_noun), \n",
    "       #ELSE, # исключение исключения\n",
    "    #seq([ alt(W('say'),W('says')),                 p_phrase      ], r_SKAZHI_phrase),\n",
    "    seq([ alt(W('say'),W('says')), W(':'),         p_phrase      ], r_SKAZHI_c_phrase),\n",
    "    seq([ alt(W('say'),W('says')),         W('\"'), p_text, W('\"')], r_SKAZHI_q_text),\n",
    "    seq([ alt(W('say'),W('says')), W(':'), W('\"'), p_text, W('\"')], r_SKAZHI_c_q_text), \n",
    "ELSE,\n",
    "    seq([ p_verb3, p_noun ]         ,r_verb_noun),    #ELSE, # переход к следующему уровню\n",
    "    seq([ p_verb3, W('no'), p_noun ],r_NE_verb_noun),    #ELSE, # переход к следующему уровню\n",
    "    p_verb3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verb1: кто (тоже) делает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_to_verb(_t,_v): return StVerb([\n",
    "    I(maindep=_v,         form='neopr', attrs_from_left=_t)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_noun_verb(n,v): return StVerb([\n",
    "    I(ip=n),\n",
    "    I(main=v,   form='nast', pers=n.pers, chis=n.chis, rod=n.rod)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_verb1_1(s,p): return p_alt(s,p,\n",
    "    pe_HAVE_noun,                           \n",
    "ELSE,\n",
    "    seq([ p_noun, p_verb2 ],r_noun_verb),\n",
    "    seq([ W('to'), p_verb2 ],r_to_verb),   #ELSE, # переход к следующему уровню\n",
    "    p_verb2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_noun_TOZHE_verb(_n, _v, _t): return StVerb([\n",
    "    I(ip=_n),\n",
    "    I(nodep=S('тоже',_t.attrs)),\n",
    "    I(main=_v,   form='nast', pers=_n.pers, chis=_n.chis, rod=_n.rod)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_verb1(s,p): return p_alt(s,p,\n",
    "    seq([ p_noun, p_verb1_1, W('too') ],r_noun_TOZHE_verb), #ELSE, # переход к следующему уровню\n",
    "    p_verb1_1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### verb: сделать одно и/но сделать сдругое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_verb_NO_verb(_v1_,_c_,_but_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=_c_),\n",
    "    I(nodep=S('но',_c_.attrs)),\n",
    "    I(nodep=_v2_)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_verb_c_verb(_v1_,_c_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=_c_),\n",
    "    I(nodep=_v2_)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def r_verb_I_verb(_v1_,_i_,_v2_):    return StC([\n",
    "    I(nodep=_v1_),\n",
    "    I(nodep=S('и',_i_.attrs)),\n",
    "    I(nodep=_v2_)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_verb(s,p): return p_alt(s,p,\n",
    "    seq([ p_verb1, W(','), p_verb1 ]          ,r_verb_c_verb),   \n",
    "    seq([ p_verb1, W(','), W('but'), p_verb1 ],r_verb_NO_verb),   \n",
    "    seq([ p_verb1, W('and'), p_verb1 ]        ,r_verb_I_verb),\n",
    "    #ELSE, # переход к следующему уровню\n",
    "    p_verb1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Фразы, предложения, текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@debug_pp\n",
    "def p_phrase(s,p): \n",
    "    rezs=[]\n",
    "    rezs+=p_verb(s,p)\n",
    "    if len(rezs)>0: return rezs\n",
    "    rezs+=p_noun(s,p)\n",
    "    if len(rezs)>0: return rezs\n",
    "    rezs+=p_noun_dp(s,p)\n",
    "    if len(rezs)>0: return rezs\n",
    "    rezs+=p_adj(s,p)\n",
    "    return rezs\n",
    "#    return p_alt(s,p,\n",
    "#        p_verb,    ELSE,\n",
    "#        p_noun,    ELSE,\n",
    "#        p_noun_dp, ELSE,\n",
    "#        p_adj\n",
    "#    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_proper={}# имена собственные\n",
    "@debug_pp\n",
    "def p_sentence(s,p):\n",
    "    first_capital = s[p]=='I' or ch_title in s[p].attrs.changers\n",
    "    def r_sentence(ph,d):\n",
    "        rez=StC([I(nodep=ph),I(punct=d)])\n",
    "        if first_capital: rez.attrs.changers|={ch_sentence}\n",
    "        return rez\n",
    "    restore_title=False\n",
    "    if ch_title in s[p].attrs.changers and s[p] not in dict_proper:\n",
    "        s[p].attrs.changers-={ch_title}\n",
    "        s[p].attrs.changers|={ch_anti_sentence}\n",
    "        restore_title=True\n",
    "    \n",
    "    rezs=seq([p_phrase,alt(W('.'),W('!'))],r_sentence)(s,p)\n",
    "    \n",
    "    if restore_title:\n",
    "        s[p].attrs.changers|={ch_title}\n",
    "        s[p].attrs.changers-={ch_anti_sentence}\n",
    "    return rezs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def maxlen_filter(patt,s,p): #\n",
    "    rezs=patt(s,p)\n",
    "    m=0\n",
    "    im=set()\n",
    "    for i in range(len(rezs)):\n",
    "        if rezs[i][0]>m:\n",
    "            m=rezs[i][0]\n",
    "            im={i}\n",
    "        elif rezs[i][0]==m:\n",
    "            im.add(i)\n",
    "    long_rezs= [rezs[i] for i in im]\n",
    "    if len(long_rezs)>1:\n",
    "        warning('multiple results:')\n",
    "        warning(SAttrs.join(s[p:m]))\n",
    "        for void,r in long_rezs:\n",
    "            warning(str(r))\n",
    "    return [] if len(long_rezs)==0 else [long_rezs[0]]\n",
    "\n",
    "@debug_pp\n",
    "def p_text(s,p):\n",
    "    rez=[]\n",
    "    while p<len(s):\n",
    "        rezs=maxlen_filter(p_sentence,s,p)\n",
    "        if len(rezs)==0: break\n",
    "        p1,r1=rezs[0]\n",
    "        p=p1\n",
    "        rez.append(I(nodep=r1))\n",
    "    if len(rez)>0:\n",
    "        return [(p,StC(rez))]\n",
    "    else:\n",
    "        return maxlen_filter(p_phrase,s,p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _en2ru(s): # main\n",
    "    s=[ i for i in tokenizer(s)]\n",
    "    if len(s)==0:\n",
    "        warning('no tokens')\n",
    "        return ''\n",
    "    rezs= p_text(s,0)\n",
    "    if len(rezs)==0:\n",
    "        warning('NO RESULTS AT ALL')\n",
    "        return ''\n",
    "    p,r1 = rezs[0]\n",
    "    if p!=len(s):\n",
    "        warning('NOT PARSED:\\n'+SAttrs().join(s[p:]))\n",
    "    return r1.tostr()\n",
    "\n",
    "def en2ru(s):\n",
    "    global DEBUGGING\n",
    "    DEBUGGING=False\n",
    "    return _en2ru(s)\n",
    "\n",
    "def d_en2ru(s):\n",
    "    global DEBUGGING\n",
    "    l_d = DEBUGGING\n",
    "    DEBUGGING=True\n",
    "    r=_en2ru(s)\n",
    "    DEBUGGING=l_d\n",
    "    return r\n",
    "\n",
    "def pr_en2ru(s):\n",
    "    print(\"'''\"+en2ru(s)+\"'''\")\n",
    "    \n",
    "def parsepat(s,patt):\n",
    "    s=[ i for i in tokenizer(s)]\n",
    "    return patt(s,0)\n",
    "\n",
    "def d_parsepat(s,patt):\n",
    "    global DEBUGGING\n",
    "    l_d = DEBUGGING\n",
    "    DEBUGGING=True\n",
    "    r=parsepat(s,patt)\n",
    "    DEBUGGING=l_d\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def decline(s,pads=['ip','rp','dp','vp','tp','pp']):\n",
    "    s=[ i for i in tokenizer(s)]\n",
    "    # добавить дочитывание точки и остаточных пробелов\n",
    "    rezs=[res for pos,res in p_noun(s,0) if pos==len(s)]\n",
    "    if len(rezs)!=1:\n",
    "        raise TextError(rezs)\n",
    "    tmp=rezs[0]\n",
    "    \n",
    "    m=[]\n",
    "    for p in pads:\n",
    "        #print(str(tmp))\n",
    "        prompt= \\\n",
    "            '' if p=='ip' else\\\n",
    "            'нет ' if p=='rp' else\\\n",
    "            'дать ' if p=='dp' else\\\n",
    "            'вижу ' if p=='vp' else\\\n",
    "            'творю ' if p=='tp' else\\\n",
    "            'думаю о ' if p=='pp' else\\\n",
    "            throw(ValueError('bad pad: '+p))\n",
    "        #rez=deepcopy(tmp)\n",
    "        tmp.pad=p\n",
    "        m.append(prompt+tmp.tostr())#        print(prompt+str(tmp))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "    КОДИТЬ И ДЕБАЖИТЬ ТЕКУЩЕЕ\n",
    "    9)  (находится) на/в\n",
    "    10) вопросы-ответы\n",
    "        считать от до\n",
    "        ловить\n",
    "    11) сколько\n",
    "    13) где\n",
    "    14) какого цвета\n",
    "        КОНТЕКСТ\n",
    "    15) посмотри\n",
    "\n",
    "копирование и подтягивание в отладке паттернов\n",
    "отладка правил\n",
    "\n",
    "автовыбор склонений/спряжений для существительных с одним числом, прилагательных и глаголов\n",
    "регламентировать использование attrs-ов в правилах и только потом приступать к контекстам\n",
    "сделать устранение конфликтов исключений\n",
    "\n",
    "на потом: \n",
    "\tзадание глобального контекста (задание дефолтных правил)\n",
    "\tвыбор паттернов и правил в зависимости от времени \n",
    "\n",
    "работа с деревом вглубь:\n",
    "\tпросмотр вглубь возможен\n",
    "\t\n",
    "\tпередача в паттерны 3го объекта\n",
    "\t\ts - string\n",
    "\t\tp - point\n",
    "\t\tc - context\n",
    "\t\t\n",
    "\tу каждого узла ссылка на правило и его аргументы\n",
    "\t\t- как был получен этот узел\n",
    "\t... у каждого узла ссылка на паттерн и позицию - во враппере\n",
    "\t\tа также номер альтернативы - в seq\n",
    "\t\tили ссылка на группу правил\n",
    "\tв узлах дерева поля \n",
    "\t\tcontext_dep\n",
    "\t\t\tTrue - узел зависит от контекста\n",
    "\t\t\t\tссылка на правило, также принимат контекст\n",
    "\t\t\tFalse - узел не зависит от контекста\n",
    "\t\tcontect_dep_srcs - массив номеров - \n",
    "\t\t\tкакие аргументы правила зависят от контекста (или их потомки зависят от контекста)\n",
    "\t\t\tт.е. какие аргументы правила требую ремейка в случае изменения контекста\n",
    "\t\t\t\n",
    "\t\tcontext(может отсутствовать) - словарь (строка, ссылка на узел), который является контекстом\n",
    "\t\t\t- устанавливается в правилах\n",
    "\tфункция context_remake(node,context)\n",
    "\n",
    "watch, двое, трое, пятеро\n",
    "\n",
    "написать везде строки документации\n",
    "написать инструкцию как пользоваться\n",
    "\n",
    "...\n",
    "открывающиеся кавычки\n",
    "\n",
    "для больших текстов p_sentence будет делать срез со своей позции до конца\n",
    "    - чтобы обновить кэши ф-ций\n",
    "\n",
    "исключения парсить, если регулярным образом распарсилось\n",
    "    каждая функция будет с аргументом парсить или нет исключения\n",
    "\n",
    "атрибуты слов: (теги)\n",
    "отображение открывающейся кавычки (SAttrs.join)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decline('two watches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я вижу джем и одну чашку.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('I see jam and one cup.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('''''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('''''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ru('''''')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
